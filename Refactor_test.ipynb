{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import scripts.proj1_helpers as helper\n",
    "import run as run\n",
    "import implementations as imp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import cross_validation as cv\n",
    "from preprocessor import Preprocessor\n",
    "from least_squares import LeastSquares\n",
    "from model_ensembler import Model_Ensembler\n",
    "from logistic import LogisticRegression\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train, x_train, ids_train = helper.load_csv_data('train.csv')\n",
    "y_test, x_test, ids_test = helper.load_csv_data('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "half_index = int(x_train.shape[0] / 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess option 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_train(x_tr, deg=1):\n",
    "    x = x_tr.copy()\n",
    "    stds = np.std(x, axis=0)\n",
    "    deleted_cols_ids = np.where(stds == 0)\n",
    "    x = np.delete(x, deleted_cols_ids, axis=1)\n",
    "    run.mean_spec(x)\n",
    "    x = run.standardize(x)\n",
    "    return x, deleted_cols_ids\n",
    "\n",
    "def preprocess_test(x_te, dependency, deg=1): \n",
    "    x = x_te.copy()\n",
    "    stds = np.std(x, axis=0)\n",
    "    x = np.delete(x, dependency, axis=1)\n",
    "    run.mean_spec(x)\n",
    "    x = run.standardize(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train, dependency = preprocess_train(x_train)\n",
    "x_test = preprocess_test(x_test, dependency)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess option 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess(x_train, x_test, deg=1):\n",
    "    x_train_end = x_train.shape[0]\n",
    "    \n",
    "    x_stacked = np.vstack((x_train, x_test))\n",
    "    \n",
    "    x = x_stacked.copy()\n",
    "    stds = np.std(x, axis=0)\n",
    "    deleted_cols_ids = np.where(stds == 0)\n",
    "    x = np.delete(x, deleted_cols_ids, axis=1)\n",
    "    run.mean_spec(x)\n",
    "    x = run.standardize(x)\n",
    "    #x = run.polynomial_enhancement(x, deg)\n",
    "    return x[:x_train_end], x[x_train_end:]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train, x_test = preprocess(x_train, x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "least_square_model_1 = LeastSquares(degree=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1 / 5\n",
      "Step 2 / 5\n",
      "Step 3 / 5\n"
     ]
    }
   ],
   "source": [
    "accuracy = cv.cross_validation(y_train, x_train, 5, least_square_model_1, seed=1, compute_loss=imp.rmse)\n",
    "accuracy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Garbage (kept just in case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_train(x_tr, deg=4):\n",
    "    x = x_tr.copy()\n",
    "    x = run.polynomial_enhancement(x, deg)\n",
    "    return x, None\n",
    "\n",
    "def preprocess_test(x_te, dependency, deg=4): \n",
    "    x = x_te.copy()\n",
    "    x = run.polynomial_enhancement(x, deg)\n",
    "    return x\n",
    "\n",
    "preprocess_train_model_1 = lambda x_tr: preprocess_train(x_tr, deg=4)\n",
    "preprocess_test_model_1 = lambda x_te, dependency: preprocess_test(x_te, dependency, deg=4)    \n",
    "\n",
    "def preprocess_train_meta_model(x_tr, deg=4):\n",
    "    x = x_tr.copy()\n",
    "    stacked_x = np.tile(x, deg)\n",
    "    power_vec = np.repeat(np.array(range(1, deg + 1)), x.shape[1])\n",
    "    return stacked_x ** power_vec, None\n",
    "    \n",
    "def preprocess_test_meta_model(x_te, dependency, deg=4):\n",
    "    x = x_te.copy()\n",
    "    stacked_x = np.tile(x, deg)\n",
    "    power_vec = np.repeat(np.array(range(1, deg + 1)), x.shape[1])\n",
    "    return stacked_x ** power_vec\n",
    "    \n",
    "\n",
    "#preprocess_train_meta_model = lambda x_tr: run.polynomial_enhancement(x_tr, 4), None\n",
    "#preprocess_test_meta_model = lambda x_te: run.polynomial_enhancement(x_te, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "least_square_model_1 = LeastSquares(degree=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor_1 = Preprocessor(preprocess_train, preprocess_test)\n",
    "preprocessor_2 = Preprocessor(preprocess_train_model_1, preprocess_test_model_1)\n",
    "preprocessor_meta = Preprocessor(preprocess_train_meta_model, preprocess_test_meta_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "least_square_model_1 = LeastSquares(preprocessor_1)\n",
    "least_square_model_2 = LeastSquares(preprocessor_2)\n",
    "\n",
    "least_square_meta_model = LeastSquares(preprocessor_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_ensembler = Model_Ensembler([least_square_model_1, least_square_model_2], least_square_meta_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "least_square_model_1 = LeastSquares(preprocessor_1)\n",
    "least_square_model_1.train(y_train[:half_index], x_train[:half_index])\n",
    "\n",
    "least_square_model_2 = LeastSquares(preprocessor_2)\n",
    "least_square_model_2.train(y_train[:half_index], x_train[:half_index])\n",
    "\n",
    "models = [least_square_model_1, least_square_model_2]\n",
    "\n",
    "stage_0_results = np.hstack([model.predict(x_train[half_index:]) for model in models])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "logistic_regression = LogisticRegression(preprocessor_1, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1 / 5\n",
      "Step 2 / 5\n",
      "Step 3 / 5\n",
      "Step 4 / 5\n",
      "Step 5 / 5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.79205999999999999,\n",
       " 0.79039999999999999,\n",
       " 0.79315999999999998,\n",
       " 0.79247999999999996,\n",
       " 0.79383999999999999]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = cv.cross_validation(y_train, x_train, 5, least_square_model_1, seed=1, compute_loss=imp.rmse)\n",
    "accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46317199999999997"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(accuracy) / len(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
