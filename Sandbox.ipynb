{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import scripts.proj1_helpers as helper\n",
    "import implementations as imp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfb = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "250000"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[df == -999.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Id\n",
      "1 Prediction\n",
      "2 DER_mass_MMC\n",
      "3 DER_mass_transverse_met_lep\n",
      "4 DER_mass_vis\n",
      "5 DER_pt_h\n",
      "6 DER_deltaeta_jet_jet\n",
      "7 DER_mass_jet_jet\n",
      "8 DER_prodeta_jet_jet\n",
      "9 DER_deltar_tau_lep\n",
      "10 DER_pt_tot\n",
      "11 DER_sum_pt\n",
      "12 DER_pt_ratio_lep_tau\n",
      "13 DER_met_phi_centrality\n",
      "14 DER_lep_eta_centrality\n",
      "15 PRI_tau_pt\n",
      "16 PRI_tau_eta\n",
      "17 PRI_tau_phi\n",
      "18 PRI_lep_pt\n",
      "19 PRI_lep_eta\n",
      "20 PRI_lep_phi\n",
      "21 PRI_met\n",
      "22 PRI_met_phi\n",
      "23 PRI_met_sumet\n",
      "24 PRI_jet_num\n",
      "25 PRI_jet_leading_pt\n",
      "26 PRI_jet_leading_eta\n",
      "27 PRI_jet_leading_phi\n",
      "28 PRI_jet_subleading_pt\n",
      "29 PRI_jet_subleading_eta\n",
      "30 PRI_jet_subleading_phi\n",
      "31 PRI_jet_all_pt\n"
     ]
    }
   ],
   "source": [
    "for i, c in enumerate(df.columns):\n",
    "    print(i, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 0, 3])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.PRI_jet_num.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "boson is -1\n",
    "\n",
    "not boson is 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250000, 30)\n",
      "(568238, 30)\n"
     ]
    }
   ],
   "source": [
    "y_train, x_train, ids_train = helper.load_csv_data('train.csv')\n",
    "y_test, x_test, ids_test = helper.load_csv_data('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of boson: 164333\n",
      "Number of other: 85667\n"
     ]
    }
   ],
   "source": [
    "print('Number of boson:', np.count_nonzero(y_train-1))\n",
    "print('Number of other:', np.count_nonzero(y_train+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train[y_train < 0] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression per category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iteration=0, the loss=68977.8485262424\n",
      "Current iteration=1, the loss=68932.51986161005\n",
      "Current iteration=2, the loss=68887.28175524631\n",
      "Current iteration=3, the loss=68797.03126444355\n",
      "Current iteration=4, the loss=68662.26211527373\n",
      "Current iteration=5, the loss=68394.7309606622\n",
      "Current iteration=6, the loss=67911.27372621435\n",
      "Current iteration=7, the loss=67054.98354041662\n",
      "Current iteration=8, the loss=65584.37811401437\n",
      "Current iteration=9, the loss=63140.99437284224\n",
      "Current iteration=10, the loss=59399.56937664053\n",
      "Current iteration=11, the loss=54289.181285149316\n",
      "Current iteration=12, the loss=48465.68274430426\n",
      "Current iteration=13, the loss=43257.3739884387\n",
      "Current iteration=14, the loss=39970.08979360185\n",
      "Current iteration=15, the loss=39017.45295133925\n",
      "Current iteration=16, the loss=38947.95231161101\n",
      "Current iteration=17, the loss=38947.396117023476\n",
      "Current iteration=0, the loss=53524.825282838974\n",
      "Current iteration=1, the loss=53505.17611223441\n",
      "Current iteration=2, the loss=53485.566216934785\n",
      "Current iteration=3, the loss=53465.99552961108\n",
      "Current iteration=4, the loss=53446.46361407603\n",
      "Current iteration=5, the loss=53407.49778875851\n",
      "Current iteration=6, the loss=53349.31090569228\n",
      "Current iteration=7, the loss=53272.22845860539\n",
      "Current iteration=8, the loss=53157.63477783525\n",
      "Current iteration=9, the loss=52988.02731312455\n",
      "Current iteration=10, the loss=52747.8224062137\n",
      "Current iteration=11, the loss=52424.38772027454\n",
      "Current iteration=12, the loss=51975.00417835928\n",
      "Current iteration=13, the loss=51353.759437315544\n",
      "Current iteration=14, the loss=50538.21209814129\n",
      "Current iteration=15, the loss=49509.773635529215\n",
      "Current iteration=16, the loss=48275.17659641819\n",
      "Current iteration=17, the loss=46894.883172466216\n",
      "Current iteration=18, the loss=45473.20947882164\n",
      "Current iteration=19, the loss=44156.84817136918\n",
      "Current iteration=20, the loss=43087.5955803809\n",
      "Current iteration=21, the loss=42357.852509845485\n",
      "Current iteration=22, the loss=41965.388448189515\n",
      "Current iteration=23, the loss=41811.41979525249\n",
      "Current iteration=24, the loss=41770.28643760822\n",
      "Current iteration=25, the loss=41762.81809536279\n",
      "Current iteration=26, the loss=41761.789134155246\n",
      "Current iteration=27, the loss=41761.667266670345\n",
      "Current iteration=28, the loss=41761.65363036473\n",
      "Current iteration=29, the loss=41761.652137393\n",
      "Current iteration=30, the loss=41761.651975543245\n",
      "Current iteration=0, the loss=34795.98846410925\n",
      "Current iteration=1, the loss=34781.46251102111\n",
      "Current iteration=2, the loss=34766.96558181008\n",
      "Current iteration=3, the loss=34752.497586750935\n",
      "Current iteration=4, the loss=34738.05844281655\n",
      "Current iteration=5, the loss=34709.25212615129\n",
      "Current iteration=6, the loss=34666.23607030946\n",
      "Current iteration=7, the loss=34609.25119588981\n",
      "Current iteration=8, the loss=34524.534518700806\n",
      "Current iteration=9, the loss=34399.14721301408\n",
      "Current iteration=10, the loss=34221.56775718719\n",
      "Current iteration=11, the loss=33969.29573515027\n",
      "Current iteration=12, the loss=33612.54610042504\n",
      "Current iteration=13, the loss=33132.26665217013\n",
      "Current iteration=14, the loss=32491.74327946125\n",
      "Current iteration=15, the loss=31686.409563508387\n",
      "Current iteration=16, the loss=30724.221827134334\n",
      "Current iteration=17, the loss=29651.95097920182\n",
      "Current iteration=18, the loss=28561.7081988903\n",
      "Current iteration=19, the loss=27568.54560442359\n",
      "Current iteration=20, the loss=26780.765564428166\n",
      "Current iteration=21, the loss=26258.017198448157\n",
      "Current iteration=22, the loss=25988.231708553394\n",
      "Current iteration=23, the loss=25891.22663588412\n",
      "Current iteration=24, the loss=25869.954334081653\n",
      "Current iteration=25, the loss=25867.27997288276\n",
      "Current iteration=26, the loss=25867.06163306145\n",
      "Current iteration=27, the loss=25867.047202025573\n",
      "Current iteration=28, the loss=25867.046310326652\n",
      "Current iteration=0, the loss=15294.985686235752\n",
      "Current iteration=1, the loss=15288.796688975952\n",
      "Current iteration=2, the loss=15282.620056935555\n",
      "Current iteration=3, the loss=15276.45575704007\n",
      "Current iteration=4, the loss=15264.15791322798\n",
      "Current iteration=5, the loss=15245.79383818944\n",
      "Current iteration=6, the loss=15215.399984790622\n",
      "Current iteration=7, the loss=15167.323508327767\n",
      "Current iteration=8, the loss=15090.621574059784\n",
      "Current iteration=9, the loss=14970.340872234252\n",
      "Current iteration=10, the loss=14784.663838420198\n",
      "Current iteration=11, the loss=14506.384858539252\n",
      "Current iteration=12, the loss=14116.221786571294\n",
      "Current iteration=13, the loss=13609.73278458479\n",
      "Current iteration=14, the loss=13029.442174997539\n",
      "Current iteration=15, the loss=12459.996336329157\n",
      "Current iteration=16, the loss=12012.689418713491\n",
      "Current iteration=17, the loss=11758.12389900899\n",
      "Current iteration=18, the loss=11672.271869738117\n",
      "Current iteration=19, the loss=11660.49807209623\n",
      "Current iteration=20, the loss=11660.12062856337\n",
      "Current iteration=21, the loss=11660.118040716383\n",
      "Current iteration=0, the loss=68972.30334879791\n",
      "Current iteration=1, the loss=68926.91183882093\n",
      "Current iteration=2, the loss=68881.61101865627\n",
      "Current iteration=3, the loss=68791.23540575246\n",
      "Current iteration=4, the loss=68656.27941277613\n",
      "Current iteration=5, the loss=68388.37737387959\n",
      "Current iteration=6, the loss=67904.24985216749\n",
      "Current iteration=7, the loss=67046.77208750823\n",
      "Current iteration=8, the loss=65574.12557339905\n",
      "Current iteration=9, the loss=63127.34102769982\n",
      "Current iteration=10, the loss=59380.65568651345\n",
      "Current iteration=11, the loss=54262.83758397205\n",
      "Current iteration=12, the loss=48430.04835678425\n",
      "Current iteration=13, the loss=43204.51993879038\n",
      "Current iteration=14, the loss=39908.664928744794\n",
      "Current iteration=15, the loss=38958.048358513945\n",
      "Current iteration=16, the loss=38888.86381790349\n",
      "Current iteration=17, the loss=38888.312849771064\n",
      "Current iteration=0, the loss=53535.915637727936\n",
      "Current iteration=1, the loss=53516.24677571667\n",
      "Current iteration=2, the loss=53496.617103015196\n",
      "Current iteration=3, the loss=53477.02695085378\n",
      "Current iteration=4, the loss=53457.47549469069\n",
      "Current iteration=5, the loss=53418.4705391549\n",
      "Current iteration=6, the loss=53360.22605260027\n",
      "Current iteration=7, the loss=53283.06633767428\n",
      "Current iteration=8, the loss=53168.35720082452\n",
      "Current iteration=9, the loss=52998.57855843795\n",
      "Current iteration=10, the loss=52758.134327716085\n",
      "Current iteration=11, the loss=52434.376682280024\n",
      "Current iteration=12, the loss=51984.532736047295\n",
      "Current iteration=13, the loss=51362.653400240095\n",
      "Current iteration=14, the loss=50546.2582687075\n",
      "Current iteration=15, the loss=49516.72091897707\n",
      "Current iteration=16, the loss=48280.757420054164\n",
      "Current iteration=17, the loss=46898.78188221831\n",
      "Current iteration=18, the loss=45475.177677253174\n",
      "Current iteration=19, the loss=44156.73591116252\n",
      "Current iteration=20, the loss=43085.484782443644\n",
      "Current iteration=21, the loss=42354.091147488616\n",
      "Current iteration=22, the loss=41959.97072556818\n",
      "Current iteration=23, the loss=41805.73294327961\n",
      "Current iteration=24, the loss=41764.70843946715\n",
      "Current iteration=25, the loss=41757.25453334924\n",
      "Current iteration=26, the loss=41756.233863734415\n",
      "Current iteration=27, the loss=41756.112901049644\n",
      "Current iteration=28, the loss=41756.09944707423\n",
      "Current iteration=29, the loss=41756.09798407165\n",
      "Current iteration=30, the loss=41756.09782547951\n",
      "Current iteration=0, the loss=34783.51181485917\n",
      "Current iteration=1, the loss=34769.000902765685\n",
      "Current iteration=2, the loss=34754.51899599205\n",
      "Current iteration=3, the loss=34740.06600589254\n",
      "Current iteration=4, the loss=34725.64182827713\n",
      "Current iteration=5, the loss=34696.86537202435\n",
      "Current iteration=6, the loss=34653.893921506206\n",
      "Current iteration=7, the loss=34596.96808071706\n",
      "Current iteration=8, the loss=34512.33931036179\n",
      "Current iteration=9, the loss=34387.08192038006\n",
      "Current iteration=10, the loss=34209.686505036254\n",
      "Current iteration=11, the loss=33957.676172488755\n",
      "Current iteration=12, the loss=33601.29674624908\n",
      "Current iteration=13, the loss=33121.51687903507\n",
      "Current iteration=14, the loss=32481.661877874125\n",
      "Current iteration=15, the loss=31677.17434661411\n",
      "Current iteration=16, the loss=30716.012354349026\n",
      "Current iteration=17, the loss=29644.91689543795\n",
      "Current iteration=18, the loss=28555.93374158949\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iteration=19, the loss=27567.011646858453\n",
      "Current iteration=20, the loss=26779.089474076904\n",
      "Current iteration=21, the loss=26257.286996992203\n",
      "Current iteration=22, the loss=25987.437482732323\n",
      "Current iteration=23, the loss=25890.144462286353\n",
      "Current iteration=24, the loss=25868.71857319682\n",
      "Current iteration=25, the loss=25866.008007578\n",
      "Current iteration=26, the loss=25865.785115091694\n",
      "Current iteration=27, the loss=25865.770139464727\n",
      "Current iteration=28, the loss=25865.769206454795\n",
      "Current iteration=0, the loss=15301.917158041353\n",
      "Current iteration=1, the loss=15295.719077381222\n",
      "Current iteration=2, the loss=15289.533382076701\n",
      "Current iteration=3, the loss=15283.360038036193\n",
      "Current iteration=4, the loss=15271.044148227855\n",
      "Current iteration=5, the loss=15252.653120796987\n",
      "Current iteration=6, the loss=15222.21466013501\n",
      "Current iteration=7, the loss=15174.067635802778\n",
      "Current iteration=8, the loss=15097.253129658864\n",
      "Current iteration=9, the loss=14976.795956042039\n",
      "Current iteration=10, the loss=14790.846529808372\n",
      "Current iteration=11, the loss=14512.159667744461\n",
      "Current iteration=12, the loss=14121.425613635034\n",
      "Current iteration=13, the loss=13614.197796871917\n",
      "Current iteration=14, the loss=13030.55015026559\n",
      "Current iteration=15, the loss=12459.737209451521\n",
      "Current iteration=16, the loss=12011.79204699673\n",
      "Current iteration=17, the loss=11758.255199694966\n",
      "Current iteration=18, the loss=11673.312638686246\n",
      "Current iteration=19, the loss=11661.87578721955\n",
      "Current iteration=20, the loss=11661.519607584683\n",
      "Current iteration=21, the loss=11661.517239290642\n",
      "Current iteration=0, the loss=68969.53076007568\n",
      "Current iteration=1, the loss=68924.23291440183\n",
      "Current iteration=2, the loss=68879.02556622315\n",
      "Current iteration=3, the loss=68788.83643201417\n",
      "Current iteration=4, the loss=68654.15891899532\n",
      "Current iteration=5, the loss=68386.80967792643\n",
      "Current iteration=6, the loss=67903.68114230601\n",
      "Current iteration=7, the loss=67047.97298491692\n",
      "Current iteration=8, the loss=65578.36658507782\n",
      "Current iteration=9, the loss=63136.63935281209\n",
      "Current iteration=10, the loss=59397.73137912924\n",
      "Current iteration=11, the loss=54290.68490952001\n",
      "Current iteration=12, the loss=48470.66567529574\n",
      "Current iteration=13, the loss=43264.76523403346\n",
      "Current iteration=14, the loss=39978.069856769886\n",
      "Current iteration=15, the loss=39025.05246008625\n",
      "Current iteration=16, the loss=38955.48524898163\n",
      "Current iteration=17, the loss=38954.928459252216\n",
      "Current iteration=0, the loss=53535.22249054738\n",
      "Current iteration=1, the loss=53515.533718936706\n",
      "Current iteration=2, the loss=53495.88408276775\n",
      "Current iteration=3, the loss=53476.2736491083\n",
      "Current iteration=4, the loss=53456.70228395365\n",
      "Current iteration=5, the loss=53417.657487985554\n",
      "Current iteration=6, the loss=53359.35270601156\n",
      "Current iteration=7, the loss=53282.11235687966\n",
      "Current iteration=8, the loss=53167.284505573116\n",
      "Current iteration=9, the loss=52997.33048734197\n",
      "Current iteration=10, the loss=52756.63489280377\n",
      "Current iteration=11, the loss=52432.53747240694\n",
      "Current iteration=12, the loss=51982.234917188696\n",
      "Current iteration=13, the loss=51359.719276880416\n",
      "Current iteration=14, the loss=50542.48876142201\n",
      "Current iteration=15, the loss=49511.90958127362\n",
      "Current iteration=16, the loss=48274.68224128951\n",
      "Current iteration=17, the loss=46891.34086308161\n",
      "Current iteration=18, the loss=45466.35874460032\n",
      "Current iteration=19, the loss=44146.75799259592\n",
      "Current iteration=20, the loss=43071.941772458806\n",
      "Current iteration=21, the loss=42340.03616695808\n",
      "Current iteration=22, the loss=41946.76196852324\n",
      "Current iteration=23, the loss=41793.39394152352\n",
      "Current iteration=24, the loss=41752.78394676754\n",
      "Current iteration=25, the loss=41745.44529531085\n",
      "Current iteration=26, the loss=41744.44653622024\n",
      "Current iteration=27, the loss=41744.3289886442\n",
      "Current iteration=28, the loss=41744.31591712947\n",
      "Current iteration=29, the loss=41744.314494750855\n",
      "Current iteration=30, the loss=41744.314341497375\n",
      "Current iteration=0, the loss=34784.898109220296\n",
      "Current iteration=1, the loss=34770.39542080552\n",
      "Current iteration=2, the loss=34755.92171064785\n",
      "Current iteration=3, the loss=34741.476885928\n",
      "Current iteration=4, the loss=34727.060883200065\n",
      "Current iteration=5, the loss=34698.30071368124\n",
      "Current iteration=6, the loss=34655.35357802244\n",
      "Current iteration=7, the loss=34598.460007223955\n",
      "Current iteration=8, the loss=34513.879086242036\n",
      "Current iteration=9, the loss=34388.69254354943\n",
      "Current iteration=10, the loss=34211.397642148986\n",
      "Current iteration=11, the loss=33959.52980075781\n",
      "Current iteration=12, the loss=33603.351904032555\n",
      "Current iteration=13, the loss=33123.842582269805\n",
      "Current iteration=14, the loss=32484.347093924236\n",
      "Current iteration=15, the loss=31680.30885620077\n",
      "Current iteration=16, the loss=30719.674930809695\n",
      "Current iteration=17, the loss=29649.151287028693\n",
      "Current iteration=18, the loss=28560.719954105414\n",
      "Current iteration=19, the loss=27569.27909758833\n",
      "Current iteration=20, the loss=26782.986103104726\n",
      "Current iteration=21, the loss=26261.37961018562\n",
      "Current iteration=22, the loss=25992.320903058004\n",
      "Current iteration=23, the loss=25895.650978865408\n",
      "Current iteration=24, the loss=25874.4718037982\n",
      "Current iteration=25, the loss=25871.811321946683\n",
      "Current iteration=26, the loss=25871.594331428172\n",
      "Current iteration=27, the loss=25871.57988074688\n",
      "Current iteration=28, the loss=25871.57898064186\n",
      "Current iteration=0, the loss=15303.996599583032\n",
      "Current iteration=1, the loss=15297.790364871169\n",
      "Current iteration=2, the loss=15291.596531568113\n",
      "Current iteration=3, the loss=15285.415065243309\n",
      "Current iteration=4, the loss=15273.082972470105\n",
      "Current iteration=5, the loss=15254.667751878489\n",
      "Current iteration=6, the loss=15224.189246223048\n",
      "Current iteration=7, the loss=15175.978861860925\n",
      "Current iteration=8, the loss=15099.06328246887\n",
      "Current iteration=9, the loss=14978.447491849363\n",
      "Current iteration=10, the loss=14792.252861430381\n",
      "Current iteration=11, the loss=14513.1971523098\n",
      "Current iteration=12, the loss=14121.941007020618\n",
      "Current iteration=13, the loss=13614.020543405331\n",
      "Current iteration=14, the loss=13029.53681980553\n",
      "Current iteration=15, the loss=12457.827017388847\n",
      "Current iteration=16, the loss=12009.849332048841\n",
      "Current iteration=17, the loss=11755.460725317205\n",
      "Current iteration=18, the loss=11669.850446380668\n",
      "Current iteration=19, the loss=11658.230819138307\n",
      "Current iteration=20, the loss=11657.867252650898\n",
      "Current iteration=21, the loss=11657.864887344664\n",
      "Current iteration=0, the loss=68972.30334879791\n",
      "Current iteration=1, the loss=68926.96005698571\n",
      "Current iteration=2, the loss=68881.70735094452\n",
      "Current iteration=3, the loss=68791.42773263529\n",
      "Current iteration=4, the loss=68656.61509937255\n",
      "Current iteration=5, the loss=68388.99762617462\n",
      "Current iteration=6, the loss=67905.38439531683\n",
      "Current iteration=7, the loss=67048.81793267827\n",
      "Current iteration=8, the loss=65577.73828088389\n",
      "Current iteration=9, the loss=63133.56661057799\n",
      "Current iteration=10, the loss=59390.92818046924\n",
      "Current iteration=11, the loss=54278.80503949424\n",
      "Current iteration=12, the loss=48452.940264334386\n",
      "Current iteration=13, the loss=43234.35420149593\n",
      "Current iteration=14, the loss=39943.739001010275\n",
      "Current iteration=15, the loss=38994.92945862456\n",
      "Current iteration=16, the loss=38925.8814947935\n",
      "Current iteration=17, the loss=38925.33220067598\n",
      "Current iteration=0, the loss=53542.153962352975\n",
      "Current iteration=1, the loss=53522.493317941684\n",
      "Current iteration=2, the loss=53502.872124400245\n",
      "Current iteration=3, the loss=53483.28994608696\n",
      "Current iteration=4, the loss=53463.74695459383\n",
      "Current iteration=5, the loss=53424.75829687489\n",
      "Current iteration=6, the loss=53366.53743370968\n",
      "Current iteration=7, the loss=53289.41028232432\n",
      "Current iteration=8, the loss=53174.74886891284\n",
      "Current iteration=9, the loss=53005.04056352819\n",
      "Current iteration=10, the loss=52764.69213027536\n",
      "Current iteration=11, the loss=52441.061844854186\n",
      "Current iteration=12, the loss=51991.40542970782\n",
      "Current iteration=13, the loss=51369.79171783695\n",
      "Current iteration=14, the loss=50553.72102327329\n",
      "Current iteration=15, the loss=49524.58743236048\n",
      "Current iteration=16, the loss=48300.069660239125\n",
      "Current iteration=17, the loss=46924.94456441815\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iteration=18, the loss=45503.419264348835\n",
      "Current iteration=19, the loss=44183.08314743419\n",
      "Current iteration=20, the loss=43107.37337375026\n",
      "Current iteration=21, the loss=42370.84680542411\n",
      "Current iteration=22, the loss=41973.15892854593\n",
      "Current iteration=23, the loss=41816.16676783526\n",
      "Current iteration=24, the loss=41774.11802539455\n",
      "Current iteration=25, the loss=41766.46140543129\n",
      "Current iteration=26, the loss=41765.411702584934\n",
      "Current iteration=27, the loss=41765.28722943625\n",
      "Current iteration=28, the loss=41765.27338155506\n",
      "Current iteration=29, the loss=41765.271875678445\n",
      "Current iteration=30, the loss=41765.27171242274\n",
      "Current iteration=0, the loss=34775.887195873016\n",
      "Current iteration=1, the loss=34761.370262559016\n",
      "Current iteration=2, the loss=34746.88233194833\n",
      "Current iteration=3, the loss=34732.42332048503\n",
      "Current iteration=4, the loss=34717.993152361094\n",
      "Current iteration=5, the loss=34689.204731283855\n",
      "Current iteration=6, the loss=34646.21540697438\n",
      "Current iteration=7, the loss=34589.265903770014\n",
      "Current iteration=8, the loss=34504.60190408739\n",
      "Current iteration=9, the loss=34379.29240375681\n",
      "Current iteration=10, the loss=34201.823178283594\n",
      "Current iteration=11, the loss=33949.70753841381\n",
      "Current iteration=12, the loss=33593.17865410841\n",
      "Current iteration=13, the loss=33113.1957529383\n",
      "Current iteration=14, the loss=32473.06503263473\n",
      "Current iteration=15, the loss=31668.217590653454\n",
      "Current iteration=16, the loss=30706.596257949608\n",
      "Current iteration=17, the loss=29634.926868509392\n",
      "Current iteration=18, the loss=28545.24785927038\n",
      "Current iteration=19, the loss=27552.541005980383\n",
      "Current iteration=20, the loss=26765.076572541744\n",
      "Current iteration=21, the loss=26242.52459278146\n",
      "Current iteration=22, the loss=25972.849315616077\n",
      "Current iteration=23, the loss=25875.888980540374\n",
      "Current iteration=24, the loss=25854.6264187592\n",
      "Current iteration=25, the loss=25851.953089513754\n",
      "Current iteration=26, the loss=25851.73482038027\n",
      "Current iteration=27, the loss=25851.720393720592\n",
      "Current iteration=28, the loss=25851.719502285232\n",
      "Current iteration=0, the loss=15303.303452402472\n",
      "Current iteration=1, the loss=15297.091519646892\n",
      "Current iteration=2, the loss=15290.89200012301\n",
      "Current iteration=3, the loss=15284.704857841603\n",
      "Current iteration=4, the loss=15272.361444316362\n",
      "Current iteration=5, the loss=15253.929312505208\n",
      "Current iteration=6, the loss=15223.422824592224\n",
      "Current iteration=7, the loss=15175.168185442753\n",
      "Current iteration=8, the loss=15098.18194679421\n",
      "Current iteration=9, the loss=14977.455350313117\n",
      "Current iteration=10, the loss=14791.08962084074\n",
      "Current iteration=11, the loss=14511.777163854491\n",
      "Current iteration=12, the loss=14120.160056943558\n",
      "Current iteration=13, the loss=13611.76718950432\n",
      "Current iteration=14, the loss=13026.729242077123\n",
      "Current iteration=15, the loss=12454.450736933248\n",
      "Current iteration=16, the loss=12005.976126321737\n",
      "Current iteration=17, the loss=11750.952821666291\n",
      "Current iteration=18, the loss=11665.369621790142\n",
      "Current iteration=19, the loss=11653.814857916044\n",
      "Current iteration=20, the loss=11653.45368550046\n",
      "Current iteration=21, the loss=11653.45133715351\n",
      "Current iteration=0, the loss=68957.74725800616\n",
      "Current iteration=1, the loss=68912.41682615849\n",
      "Current iteration=2, the loss=68867.17695548049\n",
      "Current iteration=3, the loss=68776.92295414733\n",
      "Current iteration=4, the loss=68642.14857068179\n",
      "Current iteration=5, the loss=68374.60702791951\n",
      "Current iteration=6, the loss=67891.13106840666\n",
      "Current iteration=7, the loss=67034.80759841009\n",
      "Current iteration=8, the loss=65564.14522372845\n",
      "Current iteration=9, the loss=63120.667248582715\n",
      "Current iteration=10, the loss=59379.09365519221\n",
      "Current iteration=11, the loss=54268.45292280906\n",
      "Current iteration=12, the loss=48444.43226038184\n",
      "Current iteration=13, the loss=43234.976096306775\n",
      "Current iteration=14, the loss=39943.428822085254\n",
      "Current iteration=15, the loss=38991.37647879104\n",
      "Current iteration=16, the loss=38921.90064747309\n",
      "Current iteration=17, the loss=38921.34518650189\n",
      "Current iteration=0, the loss=53545.619698255774\n",
      "Current iteration=1, the loss=53525.95491525356\n",
      "Current iteration=2, the loss=53506.32934213064\n",
      "Current iteration=3, the loss=53486.74306170872\n",
      "Current iteration=4, the loss=53467.19576606579\n",
      "Current iteration=5, the loss=53428.19866683433\n",
      "Current iteration=6, the loss=53369.965093194136\n",
      "Current iteration=7, the loss=53292.820823273345\n",
      "Current iteration=8, the loss=53178.13587466532\n",
      "Current iteration=9, the loss=53008.390837255814\n",
      "Current iteration=10, the loss=52767.994174090396\n",
      "Current iteration=11, the loss=52444.30067816087\n",
      "Current iteration=12, the loss=51994.55839210438\n",
      "Current iteration=13, the loss=51372.824728876854\n",
      "Current iteration=14, the loss=50556.61571931368\n",
      "Current iteration=15, the loss=49527.35262402746\n",
      "Current iteration=16, the loss=48302.80006481005\n",
      "Current iteration=17, the loss=46927.81900016956\n",
      "Current iteration=18, the loss=45506.744557838865\n",
      "Current iteration=19, the loss=44187.24816590288\n",
      "Current iteration=20, the loss=43112.65850101972\n",
      "Current iteration=21, the loss=42378.688095326404\n",
      "Current iteration=22, the loss=41981.00904896437\n",
      "Current iteration=23, the loss=41824.277653274046\n",
      "Current iteration=24, the loss=41782.1614944522\n",
      "Current iteration=25, the loss=41774.457135725796\n",
      "Current iteration=26, the loss=41773.39498514816\n",
      "Current iteration=27, the loss=41773.2682794757\n",
      "Current iteration=28, the loss=41773.254097717276\n",
      "Current iteration=29, the loss=41773.25254496872\n",
      "Current iteration=30, the loss=41773.25237664212\n",
      "Current iteration=0, the loss=34786.97755076197\n",
      "Current iteration=1, the loss=34772.478270088024\n",
      "Current iteration=2, the loss=34758.007963379176\n",
      "Current iteration=3, the loss=34743.56654217229\n",
      "Current iteration=4, the loss=34729.1539210307\n",
      "Current iteration=5, the loss=34700.40052052584\n",
      "Current iteration=6, the loss=34657.46349193071\n",
      "Current iteration=7, the loss=34600.583299372185\n",
      "Current iteration=8, the loss=34516.0223010936\n",
      "Current iteration=9, the loss=34390.86530259691\n",
      "Current iteration=10, the loss=34213.61219502812\n",
      "Current iteration=11, the loss=33961.80392773818\n",
      "Current iteration=12, the loss=33605.71088286685\n",
      "Current iteration=13, the loss=33126.317239928365\n",
      "Current iteration=14, the loss=32486.98002689777\n",
      "Current iteration=15, the loss=31683.149019761324\n",
      "Current iteration=16, the loss=30722.78158677814\n",
      "Current iteration=17, the loss=29652.58431857352\n",
      "Current iteration=18, the loss=28569.019070559938\n",
      "Current iteration=19, the loss=27579.289498268077\n",
      "Current iteration=20, the loss=26792.41592542239\n",
      "Current iteration=21, the loss=26269.08681272245\n",
      "Current iteration=22, the loss=25998.632003689025\n",
      "Current iteration=23, the loss=25900.7504816318\n",
      "Current iteration=24, the loss=25879.08166523823\n",
      "Current iteration=25, the loss=25876.321192687905\n",
      "Current iteration=26, the loss=25876.09223174185\n",
      "Current iteration=27, the loss=25876.076847390497\n",
      "Current iteration=28, the loss=25876.075881072586\n",
      "Current iteration=0, the loss=15303.303452402472\n",
      "Current iteration=1, the loss=15297.108680203424\n",
      "Current iteration=2, the loss=15290.926286937596\n",
      "Current iteration=3, the loss=15284.756238569984\n",
      "Current iteration=4, the loss=15272.44692085219\n",
      "Current iteration=5, the loss=15254.06571347368\n",
      "Current iteration=6, the loss=15223.643502961491\n",
      "Current iteration=7, the loss=15175.52216480397\n",
      "Current iteration=8, the loss=15098.748630505823\n",
      "Current iteration=9, the loss=14978.355605282284\n",
      "Current iteration=10, the loss=14792.50485823568\n",
      "Current iteration=11, the loss=14513.964401536092\n",
      "Current iteration=12, the loss=14123.430442767114\n",
      "Current iteration=13, the loss=13616.44653503221\n",
      "Current iteration=14, the loss=13033.039808825255\n",
      "Current iteration=15, the loss=12462.38768519642\n",
      "Current iteration=16, the loss=12015.266668512526\n",
      "Current iteration=17, the loss=11761.1458686404\n",
      "Current iteration=18, the loss=11675.97236073869\n",
      "Current iteration=19, the loss=11664.499430130176\n",
      "Current iteration=20, the loss=11664.141922200135\n",
      "Current iteration=21, the loss=11664.139601876192\n",
      "Current iteration=0, the loss=68952.89522774224\n",
      "Current iteration=1, the loss=68907.58433137022\n",
      "Current iteration=2, the loss=68862.36395484323\n",
      "Current iteration=3, the loss=68772.14883785057\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iteration=4, the loss=68637.43250333061\n",
      "Current iteration=5, the loss=68370.00618915122\n",
      "Current iteration=6, the loss=67886.73843113237\n",
      "Current iteration=7, the loss=67030.78345751428\n",
      "Current iteration=8, the loss=65560.75237006116\n",
      "Current iteration=9, the loss=63118.31446947258\n",
      "Current iteration=10, the loss=59378.288663632666\n",
      "Current iteration=11, the loss=54269.56410320113\n",
      "Current iteration=12, the loss=48447.08412475831\n",
      "Current iteration=13, the loss=43237.78593546616\n",
      "Current iteration=14, the loss=39945.4179164038\n",
      "Current iteration=15, the loss=38993.14311132945\n",
      "Current iteration=16, the loss=38923.694335599794\n",
      "Current iteration=17, the loss=38923.139409806536\n",
      "Current iteration=0, the loss=53541.46081517242\n",
      "Current iteration=1, the loss=53521.80816720066\n",
      "Current iteration=2, the loss=53502.194755953395\n",
      "Current iteration=3, the loss=53482.62037678832\n",
      "Current iteration=4, the loss=53463.085395271155\n",
      "Current iteration=5, the loss=53424.11176149109\n",
      "Current iteration=6, the loss=53365.913003809175\n",
      "Current iteration=7, the loss=53288.815932576166\n",
      "Current iteration=8, the loss=53174.1988833409\n",
      "Current iteration=9, the loss=53004.55878336796\n",
      "Current iteration=10, the loss=52764.309542672\n",
      "Current iteration=11, the loss=52440.81173664815\n",
      "Current iteration=12, the loss=51991.33780582794\n",
      "Current iteration=13, the loss=51369.978129299394\n",
      "Current iteration=14, the loss=50554.271637557256\n",
      "Current iteration=15, the loss=49525.633211722256\n",
      "Current iteration=16, the loss=48301.7827594287\n",
      "Current iteration=17, the loss=46927.552819432276\n",
      "Current iteration=18, the loss=45507.19697982341\n",
      "Current iteration=19, the loss=44188.26484950117\n",
      "Current iteration=20, the loss=43113.99849779514\n",
      "Current iteration=21, the loss=42380.11938296486\n",
      "Current iteration=22, the loss=41982.40456981662\n",
      "Current iteration=23, the loss=41825.623879580424\n",
      "Current iteration=24, the loss=41783.52692376014\n",
      "Current iteration=25, the loss=41775.79052624234\n",
      "Current iteration=26, the loss=41774.717197782775\n",
      "Current iteration=27, the loss=41774.58923217984\n",
      "Current iteration=28, the loss=41774.57482287876\n",
      "Current iteration=29, the loss=41774.57323559184\n",
      "Current iteration=30, the loss=41774.573062464624\n",
      "Current iteration=0, the loss=34791.82958102589\n",
      "Current iteration=1, the loss=34777.327818182384\n",
      "Current iteration=2, the loss=34762.85503588776\n",
      "Current iteration=3, the loss=34748.411147471146\n",
      "Current iteration=4, the loss=34733.99606577432\n",
      "Current iteration=5, the loss=34705.23774327637\n",
      "Current iteration=6, the loss=34662.29336931273\n",
      "Current iteration=7, the loss=34605.40341950569\n",
      "Current iteration=8, the loss=34520.827910407956\n",
      "Current iteration=9, the loss=34395.649428725694\n",
      "Current iteration=10, the loss=34218.36581009454\n",
      "Current iteration=11, the loss=33966.514331489176\n",
      "Current iteration=12, the loss=33610.35986751762\n",
      "Current iteration=13, the loss=33130.88357944973\n",
      "Current iteration=14, the loss=32491.43547009861\n",
      "Current iteration=15, the loss=31687.464714450532\n",
      "Current iteration=16, the loss=30726.932360553845\n",
      "Current iteration=17, the loss=29656.565891580358\n",
      "Current iteration=18, the loss=28568.379166972947\n",
      "Current iteration=19, the loss=27577.303985604136\n",
      "Current iteration=20, the loss=26791.518972346315\n",
      "Current iteration=21, the loss=26270.532027923833\n",
      "Current iteration=22, the loss=26002.06299347279\n",
      "Current iteration=23, the loss=25905.847493062767\n",
      "Current iteration=24, the loss=25884.72546704235\n",
      "Current iteration=25, the loss=25882.061017989512\n",
      "Current iteration=26, the loss=25881.842272690752\n",
      "Current iteration=27, the loss=25881.82759197191\n",
      "Current iteration=28, the loss=25881.826670152765\n",
      "Current iteration=0, the loss=15307.46233548583\n",
      "Current iteration=1, the loss=15301.261629615878\n",
      "Current iteration=2, the loss=15295.073314014375\n",
      "Current iteration=3, the loss=15288.8973543013\n",
      "Current iteration=4, the loss=15276.576249374591\n",
      "Current iteration=5, the loss=15258.17742827097\n",
      "Current iteration=6, the loss=15227.726081295863\n",
      "Current iteration=7, the loss=15179.558656374189\n",
      "Current iteration=8, the loss=15102.71163087009\n",
      "Current iteration=9, the loss=14982.203374688554\n",
      "Current iteration=10, the loss=14796.17502408328\n",
      "Current iteration=11, the loss=14517.369439383187\n",
      "Current iteration=12, the loss=14126.46744711162\n",
      "Current iteration=13, the loss=13619.017514807068\n",
      "Current iteration=14, the loss=13035.106198086385\n",
      "Current iteration=15, the loss=12464.026171746375\n",
      "Current iteration=16, the loss=12016.660383795797\n",
      "Current iteration=17, the loss=11762.467151857456\n",
      "Current iteration=18, the loss=11677.287033398958\n",
      "Current iteration=19, the loss=11665.813890030102\n",
      "Current iteration=20, the loss=11665.456418778482\n",
      "Current iteration=21, the loss=11665.454041335848\n",
      "Current iteration=0, the loss=68975.76908470072\n",
      "Current iteration=1, the loss=68930.4454190015\n",
      "Current iteration=2, the loss=68885.21230115724\n",
      "Current iteration=3, the loss=68794.97177506852\n",
      "Current iteration=4, the loss=68660.21749171629\n",
      "Current iteration=5, the loss=68392.7158474476\n",
      "Current iteration=6, the loss=67909.31192556628\n",
      "Current iteration=7, the loss=67053.11591304607\n",
      "Current iteration=8, the loss=65582.6711776074\n",
      "Current iteration=9, the loss=63139.54854496762\n",
      "Current iteration=10, the loss=59398.4966900584\n",
      "Current iteration=11, the loss=54288.51308393853\n",
      "Current iteration=12, the loss=48465.12561621554\n",
      "Current iteration=13, the loss=43256.14449733894\n",
      "Current iteration=14, the loss=39967.43967607673\n",
      "Current iteration=15, the loss=39013.845425244835\n",
      "Current iteration=16, the loss=38944.20863938434\n",
      "Current iteration=17, the loss=38943.65047023541\n",
      "Current iteration=0, the loss=53528.29101874177\n",
      "Current iteration=1, the loss=53508.63053893052\n",
      "Current iteration=2, the loss=53489.00932135038\n",
      "Current iteration=3, the loss=53469.42706840932\n",
      "Current iteration=4, the loss=53449.88431252713\n",
      "Current iteration=5, the loss=53410.89571106122\n",
      "Current iteration=6, the loss=53352.674811528166\n",
      "Current iteration=7, the loss=53275.547530811236\n",
      "Current iteration=8, the loss=53160.885753889284\n",
      "Current iteration=9, the loss=52991.17746232317\n",
      "Current iteration=10, the loss=52750.834137762075\n",
      "Current iteration=11, the loss=52427.20809592185\n",
      "Current iteration=12, the loss=51977.55633374978\n",
      "Current iteration=13, the loss=51355.93832636638\n",
      "Current iteration=14, the loss=50539.88152332668\n",
      "Current iteration=15, the loss=49510.772745563336\n",
      "Current iteration=16, the loss=48286.31927882488\n",
      "Current iteration=17, the loss=46911.31870660222\n",
      "Current iteration=18, the loss=45490.014830185384\n",
      "Current iteration=19, the loss=44169.99564577254\n",
      "Current iteration=20, the loss=43094.67361457897\n",
      "Current iteration=21, the loss=42359.906779816054\n",
      "Current iteration=22, the loss=41961.606421212535\n",
      "Current iteration=23, the loss=41804.55144416801\n",
      "Current iteration=24, the loss=41762.32799878265\n",
      "Current iteration=25, the loss=41754.6017191901\n",
      "Current iteration=26, the loss=41753.53637424622\n",
      "Current iteration=27, the loss=41753.40928544507\n",
      "Current iteration=28, the loss=41753.395060634866\n",
      "Current iteration=29, the loss=41753.393504283136\n",
      "Current iteration=30, the loss=41753.39333441205\n",
      "Current iteration=0, the loss=34783.51181485917\n",
      "Current iteration=1, the loss=34769.003394511165\n",
      "Current iteration=2, the loss=34754.52396011582\n",
      "Current iteration=3, the loss=34740.07343197091\n",
      "Current iteration=4, the loss=34725.65172838353\n",
      "Current iteration=5, the loss=34696.880193585355\n",
      "Current iteration=6, the loss=34653.91608693267\n",
      "Current iteration=7, the loss=34597.00003364408\n",
      "Current iteration=8, the loss=34512.385678319886\n",
      "Current iteration=9, the loss=34387.149742945076\n",
      "Current iteration=10, the loss=34209.78474362379\n",
      "Current iteration=11, the loss=33957.817318444795\n",
      "Current iteration=12, the loss=33601.49882083007\n",
      "Current iteration=13, the loss=33121.80066415774\n",
      "Current iteration=14, the loss=32482.054804598378\n",
      "Current iteration=15, the loss=31677.702723096532\n",
      "Current iteration=16, the loss=30716.698266891755\n",
      "Current iteration=17, the loss=29645.766136446717\n",
      "Current iteration=18, the loss=28556.91573849806\n",
      "Current iteration=19, the loss=27565.062186720228\n",
      "Current iteration=20, the loss=26778.367812616387\n",
      "Current iteration=21, the loss=26256.39410065824\n",
      "Current iteration=22, the loss=25987.064155099866\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iteration=23, the loss=25890.259299140398\n",
      "Current iteration=24, the loss=25869.04194362892\n",
      "Current iteration=25, the loss=25866.375801655697\n",
      "Current iteration=26, the loss=25866.15831214019\n",
      "Current iteration=27, the loss=25866.14382741106\n",
      "Current iteration=28, the loss=25866.142925171815\n",
      "Current iteration=0, the loss=15306.076041124712\n",
      "Current iteration=1, the loss=15299.865587787517\n",
      "Current iteration=2, the loss=15293.66754537347\n",
      "Current iteration=3, the loss=15287.481878855857\n",
      "Current iteration=4, the loss=15275.141403079491\n",
      "Current iteration=5, the loss=15256.713665962625\n",
      "Current iteration=6, the loss=15226.214446721768\n",
      "Current iteration=7, the loss=15177.971285892976\n",
      "Current iteration=8, the loss=15101.003369600436\n",
      "Current iteration=9, the loss=14980.305357818383\n",
      "Current iteration=10, the loss=14793.983221904662\n",
      "Current iteration=11, the loss=14514.734194105658\n",
      "Current iteration=12, the loss=14123.199064613267\n",
      "Current iteration=13, the loss=13614.891381323356\n",
      "Current iteration=14, the loss=13029.896713076343\n",
      "Current iteration=15, the loss=12455.984681771706\n",
      "Current iteration=16, the loss=12006.58947549912\n",
      "Current iteration=17, the loss=11752.391195318905\n",
      "Current iteration=18, the loss=11667.6478238713\n",
      "Current iteration=19, the loss=11656.416262706287\n",
      "Current iteration=20, the loss=11656.079327419116\n",
      "Current iteration=21, the loss=11656.077207919763\n",
      "Current iteration=0, the loss=68981.31426214518\n",
      "Current iteration=1, the loss=68936.00795658103\n",
      "Current iteration=2, the loss=68890.79216825405\n",
      "Current iteration=3, the loss=68800.5861941251\n",
      "Current iteration=4, the loss=68665.88351776819\n",
      "Current iteration=5, the loss=68398.48435533023\n",
      "Current iteration=6, the loss=67915.26557627245\n",
      "Current iteration=7, the loss=67059.39749175108\n",
      "Current iteration=8, the loss=65589.51608520796\n",
      "Current iteration=9, the loss=63147.32873870911\n",
      "Current iteration=10, the loss=59407.694630183265\n",
      "Current iteration=11, the loss=54299.53506411354\n",
      "Current iteration=12, the loss=48477.810576386444\n",
      "Current iteration=13, the loss=43269.447813307575\n",
      "Current iteration=14, the loss=39980.70073225912\n",
      "Current iteration=15, the loss=39027.60079513442\n",
      "Current iteration=16, the loss=38958.140649671695\n",
      "Current iteration=17, the loss=38957.58640913148\n",
      "Current iteration=0, the loss=53519.97325257506\n",
      "Current iteration=1, the loss=53500.29932792848\n",
      "Current iteration=2, the loss=53480.664673723266\n",
      "Current iteration=3, the loss=53461.06924860572\n",
      "Current iteration=4, the loss=53441.51298561065\n",
      "Current iteration=5, the loss=53402.49777675448\n",
      "Current iteration=6, the loss=53344.23704602975\n",
      "Current iteration=7, the loss=53267.057971158494\n",
      "Current iteration=8, the loss=53152.31813835594\n",
      "Current iteration=9, the loss=52982.49527511479\n",
      "Current iteration=10, the loss=52741.98642531537\n",
      "Current iteration=11, the loss=52418.14135826333\n",
      "Current iteration=12, the loss=51968.18657327856\n",
      "Current iteration=13, the loss=51346.153772722406\n",
      "Current iteration=14, the loss=50529.54527270855\n",
      "Current iteration=15, the loss=49499.71662258665\n",
      "Current iteration=16, the loss=48263.390973552996\n",
      "Current iteration=17, the loss=46881.002410955756\n",
      "Current iteration=18, the loss=45456.92245159626\n",
      "Current iteration=19, the loss=44137.97810133653\n",
      "Current iteration=20, the loss=43066.20770900831\n",
      "Current iteration=21, the loss=42334.3484737931\n",
      "Current iteration=22, the loss=41939.848282080835\n",
      "Current iteration=23, the loss=41785.39138014022\n",
      "Current iteration=24, the loss=41744.28827205206\n",
      "Current iteration=25, the loss=41736.817103314206\n",
      "Current iteration=26, the loss=41735.79381903853\n",
      "Current iteration=27, the loss=41735.67253458228\n",
      "Current iteration=28, the loss=41735.6590440603\n",
      "Current iteration=29, the loss=41735.65757597639\n",
      "Current iteration=30, the loss=41735.657417798466\n",
      "Current iteration=0, the loss=34785.591256400854\n",
      "Current iteration=1, the loss=34771.07397684113\n",
      "Current iteration=2, the loss=34756.585691217595\n",
      "Current iteration=3, the loss=34742.12633587581\n",
      "Current iteration=4, the loss=34727.69582036001\n",
      "Current iteration=5, the loss=34698.90669552176\n",
      "Current iteration=6, the loss=34655.91635188818\n",
      "Current iteration=7, the loss=34598.96548349629\n",
      "Current iteration=8, the loss=34514.29939766413\n",
      "Current iteration=9, the loss=34388.98687296796\n",
      "Current iteration=10, the loss=34211.51336489597\n",
      "Current iteration=11, the loss=33959.3921082707\n",
      "Current iteration=12, the loss=33602.85589767881\n",
      "Current iteration=13, the loss=33122.86486270288\n",
      "Current iteration=14, the loss=32482.727669516855\n",
      "Current iteration=15, the loss=31677.88528353429\n",
      "Current iteration=16, the loss=30716.298218228734\n",
      "Current iteration=17, the loss=29644.72635615834\n",
      "Current iteration=18, the loss=28555.2547485168\n",
      "Current iteration=19, the loss=27562.894265407387\n",
      "Current iteration=20, the loss=26775.88475513019\n",
      "Current iteration=21, the loss=26253.783501078025\n",
      "Current iteration=22, the loss=25984.42769757202\n",
      "Current iteration=23, the loss=25887.709175342534\n",
      "Current iteration=24, the loss=25866.425696213562\n",
      "Current iteration=25, the loss=25863.7352055912\n",
      "Current iteration=26, the loss=25863.513945235496\n",
      "Current iteration=27, the loss=25863.499203473235\n",
      "Current iteration=28, the loss=25863.498285121084\n",
      "Current iteration=0, the loss=15306.769188305272\n",
      "Current iteration=1, the loss=15300.560098984863\n",
      "Current iteration=2, the loss=15294.363416958966\n",
      "Current iteration=3, the loss=15288.179108677956\n",
      "Current iteration=4, the loss=15275.84134609542\n",
      "Current iteration=5, the loss=15257.417653925004\n",
      "Current iteration=6, the loss=15226.925129734478\n",
      "Current iteration=7, the loss=15178.692581276386\n",
      "Current iteration=8, the loss=15101.741603883158\n",
      "Current iteration=9, the loss=14981.070273281139\n",
      "Current iteration=10, the loss=14794.789870175593\n",
      "Current iteration=11, the loss=14515.605169048096\n",
      "Current iteration=12, the loss=14124.166896650044\n",
      "Current iteration=13, the loss=13616.005728993458\n",
      "Current iteration=14, the loss=13031.233904666244\n",
      "Current iteration=15, the loss=12457.649816649528\n",
      "Current iteration=16, the loss=12008.666089575883\n",
      "Current iteration=17, the loss=11754.837821903122\n",
      "Current iteration=18, the loss=11670.283736665022\n",
      "Current iteration=19, the loss=11659.089926287794\n",
      "Current iteration=20, the loss=11658.754576424319\n",
      "Current iteration=21, the loss=11658.752521350962\n",
      "Current iteration=0, the loss=68961.21299390895\n",
      "Current iteration=1, the loss=68915.89252601066\n",
      "Current iteration=2, the loss=68870.66259973329\n",
      "Current iteration=3, the loss=68780.42842362267\n",
      "Current iteration=4, the loss=68645.68364213881\n",
      "Current iteration=5, the loss=68378.20083202557\n",
      "Current iteration=6, the loss=67894.83095311098\n",
      "Current iteration=7, the loss=67038.69518979007\n",
      "Current iteration=8, the loss=65568.35413250659\n",
      "Current iteration=9, the loss=63125.40273766249\n",
      "Current iteration=10, the loss=59384.606323812266\n",
      "Current iteration=11, the loss=54274.919526860904\n",
      "Current iteration=12, the loss=48451.65862965635\n",
      "Current iteration=13, the loss=43235.15119416053\n",
      "Current iteration=14, the loss=39947.79853378864\n",
      "Current iteration=15, the loss=38996.90525658962\n",
      "Current iteration=16, the loss=38927.541286037966\n",
      "Current iteration=17, the loss=38926.986617736904\n",
      "Current iteration=0, the loss=53545.619698255774\n",
      "Current iteration=1, the loss=53525.940948122356\n",
      "Current iteration=2, the loss=53506.30132116228\n",
      "Current iteration=3, the loss=53486.70076866367\n",
      "Current iteration=4, the loss=53467.13937203793\n",
      "Current iteration=5, the loss=53428.11403130585\n",
      "Current iteration=6, the loss=53369.83877131048\n",
      "Current iteration=7, the loss=53292.63791135423\n",
      "Current iteration=8, the loss=53177.869180475645\n",
      "Current iteration=9, the loss=53008.00113420924\n",
      "Current iteration=10, the loss=52767.43061228425\n",
      "Current iteration=11, the loss=52443.50372698663\n",
      "Current iteration=12, the loss=51993.42628646923\n",
      "Current iteration=13, the loss=51371.241313846185\n",
      "Current iteration=14, the loss=50554.434950384064\n",
      "Current iteration=15, the loss=49524.411868385985\n",
      "Current iteration=16, the loss=48287.86791907931\n",
      "Current iteration=17, the loss=46905.32317557015\n",
      "Current iteration=18, the loss=45481.18268908117\n",
      "Current iteration=19, the loss=44162.25287161438\n",
      "Current iteration=20, the loss=43087.75179383358\n",
      "Current iteration=21, the loss=42355.70238655318\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iteration=22, the loss=41962.733298730636\n",
      "Current iteration=23, the loss=41808.84927285615\n",
      "Current iteration=24, the loss=41768.10507670207\n",
      "Current iteration=25, the loss=41760.74340030532\n",
      "Current iteration=26, the loss=41759.741579530826\n",
      "Current iteration=27, the loss=41759.6236774538\n",
      "Current iteration=28, the loss=41759.610566012634\n",
      "Current iteration=29, the loss=41759.60913934153\n",
      "Current iteration=30, the loss=41759.608985625775\n",
      "Current iteration=0, the loss=34783.51181485917\n",
      "Current iteration=1, the loss=34768.990920624594\n",
      "Current iteration=2, the loss=34754.499036276815\n",
      "Current iteration=3, the loss=34740.03607647905\n",
      "Current iteration=4, the loss=34725.601963464316\n",
      "Current iteration=5, the loss=34696.80568207481\n",
      "Current iteration=6, the loss=34653.80462558337\n",
      "Current iteration=7, the loss=34596.839575156\n",
      "Current iteration=8, the loss=34512.152458123965\n",
      "Current iteration=9, the loss=34386.80881833258\n",
      "Current iteration=10, the loss=34209.29135131732\n",
      "Current iteration=11, the loss=33957.10732991623\n",
      "Current iteration=12, the loss=33600.48228982895\n",
      "Current iteration=13, the loss=33120.37138527898\n",
      "Current iteration=14, the loss=32480.075177422234\n",
      "Current iteration=15, the loss=31675.032884919285\n",
      "Current iteration=16, the loss=30713.208442485833\n",
      "Current iteration=17, the loss=29641.38117179977\n",
      "Current iteration=18, the loss=28551.673234954455\n",
      "Current iteration=19, the loss=27559.16437082547\n",
      "Current iteration=20, the loss=26772.171283111595\n",
      "Current iteration=21, the loss=26250.281546873586\n",
      "Current iteration=22, the loss=25981.230573284007\n",
      "Current iteration=23, the loss=25884.63767821295\n",
      "Current iteration=24, the loss=25863.492235042086\n",
      "Current iteration=25, the loss=25860.83758894763\n",
      "Current iteration=26, the loss=25860.621139738036\n",
      "Current iteration=27, the loss=25860.606726589904\n",
      "Current iteration=28, the loss=25860.605828850774\n",
      "Current iteration=0, the loss=15303.303452402472\n",
      "Current iteration=1, the loss=15297.104466331779\n",
      "Current iteration=2, the loss=15290.917866422926\n",
      "Current iteration=3, the loss=15284.743619607703\n",
      "Current iteration=4, the loss=15272.425929272718\n",
      "Current iteration=5, the loss=15254.032217562708\n",
      "Current iteration=6, the loss=15223.589314151073\n",
      "Current iteration=7, the loss=15175.435241744965\n",
      "Current iteration=8, the loss=15098.609474269098\n",
      "Current iteration=9, the loss=14978.134465026618\n",
      "Current iteration=10, the loss=14792.157082212505\n",
      "Current iteration=11, the loss=14513.426604025693\n",
      "Current iteration=12, the loss=14122.625192359623\n",
      "Current iteration=13, the loss=13615.291418763762\n",
      "Current iteration=14, the loss=13033.991550286855\n",
      "Current iteration=15, the loss=12463.47198560149\n",
      "Current iteration=16, the loss=12015.199480641364\n",
      "Current iteration=17, the loss=11759.968960332195\n",
      "Current iteration=18, the loss=11673.839003040779\n",
      "Current iteration=19, the loss=11662.018652528172\n",
      "Current iteration=20, the loss=11661.639437811098\n",
      "Current iteration=21, the loss=11661.636836440593\n",
      "Current iteration=0, the loss=68957.74725800616\n",
      "Current iteration=1, the loss=68912.40980403843\n",
      "Current iteration=2, the loss=68867.16293122359\n",
      "Current iteration=3, the loss=68776.8949453836\n",
      "Current iteration=4, the loss=68642.09966979896\n",
      "Current iteration=5, the loss=68374.51664325963\n",
      "Current iteration=6, the loss=67890.96563314852\n",
      "Current iteration=7, the loss=67034.50896142509\n",
      "Current iteration=8, the loss=65563.61588585252\n",
      "Current iteration=9, the loss=63119.74499154046\n",
      "Current iteration=10, the loss=59377.5282777604\n",
      "Current iteration=11, the loss=54265.870516647265\n",
      "Current iteration=12, the loss=48440.30486869868\n",
      "Current iteration=13, the loss=43221.59790553003\n",
      "Current iteration=14, the loss=39930.26902528284\n",
      "Current iteration=15, the loss=38980.73711368366\n",
      "Current iteration=16, the loss=38911.55652506376\n",
      "Current iteration=17, the loss=38911.00507866553\n",
      "Current iteration=0, the loss=53542.153962352975\n",
      "Current iteration=1, the loss=53522.46946693141\n",
      "Current iteration=2, the loss=53502.82441010596\n",
      "Current iteration=3, the loss=53483.21864620034\n",
      "Current iteration=4, the loss=53463.65199470616\n",
      "Current iteration=5, the loss=53424.61590175373\n",
      "Current iteration=6, the loss=53366.32395838522\n",
      "Current iteration=7, the loss=53289.10156746256\n",
      "Current iteration=8, the loss=53174.30039509799\n",
      "Current iteration=9, the loss=53004.38520029025\n",
      "Current iteration=10, the loss=52763.74785439991\n",
      "Current iteration=11, the loss=52439.73073175228\n",
      "Current iteration=12, the loss=51989.52674955185\n",
      "Current iteration=13, the loss=51367.15532642618\n",
      "Current iteration=14, the loss=50550.099928099495\n",
      "Current iteration=15, the loss=49519.72827096136\n",
      "Current iteration=16, the loss=48282.714987183135\n",
      "Current iteration=17, the loss=46899.54174021291\n",
      "Current iteration=18, the loss=45474.56059247707\n",
      "Current iteration=19, the loss=44154.743390151954\n",
      "Current iteration=20, the loss=43079.474766132014\n",
      "Current iteration=21, the loss=42347.02421674014\n",
      "Current iteration=22, the loss=41953.30859142842\n",
      "Current iteration=23, the loss=41799.71390065057\n",
      "Current iteration=24, the loss=41758.99404887028\n",
      "Current iteration=25, the loss=41751.67391744581\n",
      "Current iteration=26, the loss=41750.67700051776\n",
      "Current iteration=27, the loss=41750.560354878115\n",
      "Current iteration=28, the loss=41750.547462182956\n",
      "Current iteration=29, the loss=41750.54606888336\n",
      "Current iteration=30, the loss=41750.54591865416\n",
      "Current iteration=0, the loss=34793.21587538701\n",
      "Current iteration=1, the loss=34778.71469949772\n",
      "Current iteration=2, the loss=34764.24250124929\n",
      "Current iteration=3, the loss=34749.79919577022\n",
      "Current iteration=4, the loss=34735.38470177583\n",
      "Current iteration=5, the loss=34706.627538198554\n",
      "Current iteration=6, the loss=34663.68488304244\n",
      "Current iteration=7, the loss=34606.79721134398\n",
      "Current iteration=8, the loss=34522.22510442598\n",
      "Current iteration=9, the loss=34397.0517013857\n",
      "Current iteration=10, the loss=34219.7753454616\n",
      "Current iteration=11, the loss=33967.93409473694\n",
      "Current iteration=12, the loss=33611.793932093045\n",
      "Current iteration=13, the loss=33132.33687965045\n",
      "Current iteration=14, the loss=32492.91453289344\n",
      "Current iteration=15, the loss=31688.975822123644\n",
      "Current iteration=16, the loss=30728.479150551815\n",
      "Current iteration=17, the loss=29658.14242511576\n",
      "Current iteration=18, the loss=28569.957398093822\n",
      "Current iteration=19, the loss=27578.815291474726\n",
      "Current iteration=20, the loss=26792.84403668075\n",
      "Current iteration=21, the loss=26271.53671784442\n",
      "Current iteration=22, the loss=26002.705575763437\n",
      "Current iteration=23, the loss=25906.2475372057\n",
      "Current iteration=24, the loss=25885.042008768047\n",
      "Current iteration=25, the loss=25882.363713451643\n",
      "Current iteration=26, the loss=25882.143682671813\n",
      "Current iteration=27, the loss=25882.12891219412\n",
      "Current iteration=28, the loss=25882.127984183244\n",
      "Current iteration=0, the loss=15300.530863680233\n",
      "Current iteration=1, the loss=15294.326946881603\n",
      "Current iteration=2, the loss=15288.135427624022\n",
      "Current iteration=3, the loss=15281.956272178402\n",
      "Current iteration=4, the loss=15269.628789606628\n",
      "Current iteration=5, the loss=15251.220448137254\n",
      "Current iteration=6, the loss=15220.753331164997\n",
      "Current iteration=7, the loss=15172.560958607952\n",
      "Current iteration=8, the loss=15095.674066470472\n",
      "Current iteration=9, the loss=14975.103159306951\n",
      "Current iteration=10, the loss=14788.977393512934\n",
      "Current iteration=11, the loss=14510.023127226768\n",
      "Current iteration=12, the loss=14118.903214058924\n",
      "Current iteration=13, the loss=13611.140529084245\n",
      "Current iteration=14, the loss=13026.788797073938\n",
      "Current iteration=15, the loss=12455.107334962988\n",
      "Current iteration=16, the loss=12006.214023634502\n",
      "Current iteration=17, the loss=11751.593957934952\n",
      "Current iteration=18, the loss=11666.38030314941\n",
      "Current iteration=19, the loss=11655.004127723165\n",
      "Current iteration=20, the loss=11654.661597463064\n",
      "Current iteration=21, the loss=11654.659491980174\n",
      "Current iteration=0, the loss=68987.55258677024\n",
      "Current iteration=1, the loss=68942.18916709557\n",
      "Current iteration=2, the loss=68896.91637767045\n",
      "Current iteration=3, the loss=68806.59668724047\n",
      "Current iteration=4, the loss=68671.72421052138\n",
      "Current iteration=5, the loss=68403.98794028575\n",
      "Current iteration=6, the loss=67920.1600607546\n",
      "Current iteration=7, the loss=67063.21333030396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iteration=8, the loss=65591.48076274141\n",
      "Current iteration=9, the loss=63146.22573838229\n",
      "Current iteration=10, the loss=59401.9422153553\n",
      "Current iteration=11, the loss=54287.67333864252\n",
      "Current iteration=12, the loss=48459.7931658453\n",
      "Current iteration=13, the loss=43247.52426539859\n",
      "Current iteration=14, the loss=39955.09395839751\n",
      "Current iteration=15, the loss=39003.44441592379\n",
      "Current iteration=16, the loss=38934.103696624516\n",
      "Current iteration=17, the loss=38933.55047082679\n",
      "Current iteration=0, the loss=53542.153962352975\n",
      "Current iteration=1, the loss=53522.49413762128\n",
      "Current iteration=2, the loss=53502.87357095988\n",
      "Current iteration=3, the loss=53483.29199066418\n",
      "Current iteration=4, the loss=53463.749559358665\n",
      "Current iteration=5, the loss=53424.7628159007\n",
      "Current iteration=6, the loss=53366.5439343661\n",
      "Current iteration=7, the loss=53289.41832951579\n",
      "Current iteration=8, the loss=53174.76074971179\n",
      "Current iteration=9, the loss=53005.0609596654\n",
      "Current iteration=10, the loss=52764.72372171697\n",
      "Current iteration=11, the loss=52441.10774068123\n",
      "Current iteration=12, the loss=51991.47333385434\n",
      "Current iteration=13, the loss=51369.88078937527\n",
      "Current iteration=14, the loss=50553.878465808695\n",
      "Current iteration=15, the loss=49524.84659269221\n",
      "Current iteration=16, the loss=48289.55043336202\n",
      "Current iteration=17, the loss=46908.42159235449\n",
      "Current iteration=18, the loss=45485.804397159605\n",
      "Current iteration=19, the loss=44168.48492815942\n",
      "Current iteration=20, the loss=43098.33726124208\n",
      "Current iteration=21, the loss=42367.89262831322\n",
      "Current iteration=22, the loss=41974.98842109913\n",
      "Current iteration=23, the loss=41820.81971224191\n",
      "Current iteration=24, the loss=41779.62477100167\n",
      "Current iteration=25, the loss=41772.14429555323\n",
      "Current iteration=26, the loss=41771.113609793945\n",
      "Current iteration=27, the loss=41770.99152873825\n",
      "Current iteration=28, the loss=41770.977868450165\n",
      "Current iteration=29, the loss=41770.97637289092\n",
      "Current iteration=30, the loss=41770.97621076545\n",
      "Current iteration=0, the loss=34768.26257688685\n",
      "Current iteration=1, the loss=34753.75297417259\n",
      "Current iteration=2, the loss=34739.27236462965\n",
      "Current iteration=3, the loss=34724.820654212235\n",
      "Current iteration=4, the loss=34710.39776926178\n",
      "Current iteration=5, the loss=34681.623885782334\n",
      "Current iteration=6, the loss=34638.65627417936\n",
      "Current iteration=7, the loss=34581.73556414564\n",
      "Current iteration=8, the loss=34497.114310812365\n",
      "Current iteration=9, the loss=34371.86817284556\n",
      "Current iteration=10, the loss=34194.488623742945\n",
      "Current iteration=11, the loss=33942.50075139428\n",
      "Current iteration=12, the loss=33586.15343261439\n",
      "Current iteration=13, the loss=33106.41680463966\n",
      "Current iteration=14, the loss=32466.620757291777\n",
      "Current iteration=15, the loss=31662.20857940721\n",
      "Current iteration=16, the loss=30701.141020481566\n",
      "Current iteration=17, the loss=29630.159898700287\n",
      "Current iteration=18, the loss=28541.310890009463\n",
      "Current iteration=19, the loss=27549.559902549718\n",
      "Current iteration=20, the loss=26763.1110481331\n",
      "Current iteration=21, the loss=26241.50261242022\n",
      "Current iteration=22, the loss=25972.537180426716\n",
      "Current iteration=23, the loss=25876.04546921227\n",
      "Current iteration=24, the loss=25854.836813588623\n",
      "Current iteration=25, the loss=25852.1586117889\n",
      "Current iteration=26, the loss=25851.938490597324\n",
      "Current iteration=27, the loss=25851.92382772879\n",
      "Current iteration=28, the loss=25851.92291434312\n",
      "Current iteration=0, the loss=15295.678833416312\n",
      "Current iteration=1, the loss=15289.47833631192\n",
      "Current iteration=2, the loss=15283.290229667735\n",
      "Current iteration=3, the loss=15277.114480044498\n",
      "Current iteration=4, the loss=15264.79379033755\n",
      "Current iteration=5, the loss=15246.395593396088\n",
      "Current iteration=6, the loss=15215.94527099975\n",
      "Current iteration=7, the loss=15167.779478408826\n",
      "Current iteration=8, the loss=15090.935008059794\n",
      "Current iteration=9, the loss=14970.430773294593\n",
      "Current iteration=10, the loss=14784.408537238613\n",
      "Current iteration=11, the loss=14505.611703556619\n",
      "Current iteration=12, the loss=14114.720510659494\n",
      "Current iteration=13, the loss=13607.280005766706\n",
      "Current iteration=14, the loss=13023.366007174056\n",
      "Current iteration=15, the loss=12450.685524975113\n",
      "Current iteration=16, the loss=12002.50667364343\n",
      "Current iteration=17, the loss=11749.231623473212\n",
      "Current iteration=18, the loss=11664.912285639044\n",
      "Current iteration=19, the loss=11653.758212538825\n",
      "Current iteration=20, the loss=11653.42436533148\n",
      "Current iteration=21, the loss=11653.422268192891\n",
      "Current iteration=0, the loss=68983.39370368687\n",
      "Current iteration=1, the loss=68938.07799903372\n",
      "Current iteration=2, the loss=68892.8528254227\n",
      "Current iteration=3, the loss=68802.62814702399\n",
      "Current iteration=4, the loss=68667.89753060022\n",
      "Current iteration=5, the loss=68400.44286349016\n",
      "Current iteration=6, the loss=67917.12385125278\n",
      "Current iteration=7, the loss=67061.07838812012\n",
      "Current iteration=8, the loss=65590.89304610883\n",
      "Current iteration=9, the loss=63148.20488754781\n",
      "Current iteration=10, the loss=59407.83113287927\n",
      "Current iteration=11, the loss=54298.7903603298\n",
      "Current iteration=12, the loss=48476.39883892475\n",
      "Current iteration=13, the loss=43267.805476170746\n",
      "Current iteration=14, the loss=39978.49521702952\n",
      "Current iteration=15, the loss=39024.58782343575\n",
      "Current iteration=16, the loss=38954.974052048005\n",
      "Current iteration=17, the loss=38954.41709545983\n",
      "Current iteration=0, the loss=53526.904724380656\n",
      "Current iteration=1, the loss=53507.249232696966\n",
      "Current iteration=2, the loss=53487.63290120266\n",
      "Current iteration=3, the loss=53468.05588477282\n",
      "Current iteration=4, the loss=53448.51764640189\n",
      "Current iteration=5, the loss=53409.53865829462\n",
      "Current iteration=6, the loss=53351.33223589665\n",
      "Current iteration=7, the loss=53274.22413310453\n",
      "Current iteration=8, the loss=53159.590954707295\n",
      "Current iteration=9, the loss=52989.92583294308\n",
      "Current iteration=10, the loss=52749.639082908616\n",
      "Current iteration=11, the loss=52426.09586843555\n",
      "Current iteration=12, the loss=51976.55193377135\n",
      "Current iteration=13, the loss=51355.095103731044\n",
      "Current iteration=14, the loss=50539.25874563273\n",
      "Current iteration=15, the loss=49510.426067356486\n",
      "Current iteration=16, the loss=48275.30659599779\n",
      "Current iteration=17, the loss=46894.29892973549\n",
      "Current iteration=18, the loss=45471.6965749962\n",
      "Current iteration=19, the loss=44154.23044571029\n",
      "Current iteration=20, the loss=43081.12141168236\n",
      "Current iteration=21, the loss=42350.35589136142\n",
      "Current iteration=22, the loss=41957.72238136689\n",
      "Current iteration=23, the loss=41804.63113472349\n",
      "Current iteration=24, the loss=41764.103449013724\n",
      "Current iteration=25, the loss=41756.78125444971\n",
      "Current iteration=26, the loss=41755.78477601874\n",
      "Current iteration=27, the loss=41755.66750195024\n",
      "Current iteration=28, the loss=41755.65446107611\n",
      "Current iteration=29, the loss=41755.65304207352\n",
      "Current iteration=30, the loss=41755.65288918593\n",
      "Current iteration=0, the loss=34783.51181485917\n",
      "Current iteration=1, the loss=34769.01614858073\n",
      "Current iteration=2, the loss=34754.54944925717\n",
      "Current iteration=3, the loss=34740.111620859\n",
      "Current iteration=4, the loss=34725.70258414044\n",
      "Current iteration=5, the loss=34696.9563518699\n",
      "Current iteration=6, the loss=34654.0300240831\n",
      "Current iteration=7, the loss=34597.16397311172\n",
      "Current iteration=8, the loss=34512.62395635444\n",
      "Current iteration=9, the loss=34387.49799070138\n",
      "Current iteration=10, the loss=34210.28882614105\n",
      "Current iteration=11, the loss=33958.542877524626\n",
      "Current iteration=12, the loss=33602.537449380725\n",
      "Current iteration=13, the loss=33123.260427605645\n",
      "Current iteration=14, the loss=32484.07485968907\n",
      "Current iteration=15, the loss=31680.42646825224\n",
      "Current iteration=16, the loss=30720.26019656835\n",
      "Current iteration=17, the loss=29650.26268510798\n",
      "Current iteration=18, the loss=28562.378239211575\n",
      "Current iteration=19, the loss=27571.45151399749\n",
      "Current iteration=20, the loss=26785.58075126249\n",
      "Current iteration=21, the loss=26264.27114898335\n",
      "Current iteration=22, the loss=25995.389709895433\n",
      "Current iteration=23, the loss=25898.894067648926\n",
      "Current iteration=24, the loss=25877.676637342\n",
      "Current iteration=25, the loss=25874.9965518374\n",
      "Current iteration=26, the loss=25874.776242734715\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iteration=27, the loss=25874.761566605066\n",
      "Current iteration=28, the loss=25874.76065237935\n",
      "Current iteration=0, the loss=15299.837716499673\n",
      "Current iteration=1, the loss=15293.6430459077\n",
      "Current iteration=2, the loss=15287.460753785783\n",
      "Current iteration=3, the loss=15281.290806010464\n",
      "Current iteration=4, the loss=15268.981690559083\n",
      "Current iteration=5, the loss=15250.60078148627\n",
      "Current iteration=6, the loss=15220.179062515977\n",
      "Current iteration=7, the loss=15172.058507067843\n",
      "Current iteration=8, the loss=15095.286247728767\n",
      "Current iteration=9, the loss=14974.895304542299\n",
      "Current iteration=10, the loss=14789.048027909868\n",
      "Current iteration=11, the loss=14510.514092366235\n",
      "Current iteration=12, the loss=14119.993584599877\n",
      "Current iteration=13, the loss=13613.04073773637\n",
      "Current iteration=14, the loss=13029.706004665593\n",
      "Current iteration=15, the loss=12459.198077225492\n",
      "Current iteration=16, the loss=12011.501461609478\n",
      "Current iteration=17, the loss=11758.12129168917\n",
      "Current iteration=18, the loss=11673.241532943943\n",
      "Current iteration=19, the loss=11661.815531757846\n",
      "Current iteration=20, the loss=11661.459799043521\n",
      "Current iteration=21, the loss=11661.45743417848\n",
      "Current iteration=0, the loss=68988.2457339508\n",
      "Current iteration=1, the loss=68942.92347340762\n",
      "Current iteration=2, the loss=68897.69175926891\n",
      "Current iteration=3, the loss=68807.45402394947\n",
      "Current iteration=4, the loss=68672.70390620413\n",
      "Current iteration=5, the loss=68405.2105607361\n",
      "Current iteration=6, the loss=67921.82162171885\n",
      "Current iteration=7, the loss=67065.65228799114\n",
      "Current iteration=8, the loss=65595.25399761296\n",
      "Current iteration=9, the loss=63152.211763725834\n",
      "Current iteration=10, the loss=59411.29536178015\n",
      "Current iteration=11, the loss=54301.53323300916\n",
      "Current iteration=12, the loss=48478.50905193217\n",
      "Current iteration=13, the loss=43270.138875221106\n",
      "Current iteration=14, the loss=39980.07503325788\n",
      "Current iteration=15, the loss=39029.47367152008\n",
      "Current iteration=16, the loss=38960.318011604526\n",
      "Current iteration=17, the loss=38959.768271975365\n",
      "Current iteration=0, the loss=53525.51843001954\n",
      "Current iteration=1, the loss=53505.85621686567\n",
      "Current iteration=2, the loss=53486.23337952884\n",
      "Current iteration=3, the loss=53466.649909324886\n",
      "Current iteration=4, the loss=53447.10542622661\n",
      "Current iteration=5, the loss=53408.113470696146\n",
      "Current iteration=6, the loss=53349.88737499258\n",
      "Current iteration=7, the loss=53272.75302739173\n",
      "Current iteration=8, the loss=53158.082546804195\n",
      "Current iteration=9, the loss=52988.360572177284\n",
      "Current iteration=10, the loss=52747.99557343775\n",
      "Current iteration=11, the loss=52424.342905445505\n",
      "Current iteration=12, the loss=51974.66083843059\n",
      "Current iteration=13, the loss=51353.00089264051\n",
      "Current iteration=14, the loss=50536.883742551974\n",
      "Current iteration=15, the loss=49507.723174069164\n",
      "Current iteration=16, the loss=48283.23972874928\n",
      "Current iteration=17, the loss=46908.2491287451\n",
      "Current iteration=18, the loss=45487.084816940864\n",
      "Current iteration=19, the loss=44167.29775595271\n",
      "Current iteration=20, the loss=43092.24512460616\n",
      "Current iteration=21, the loss=42357.7326576039\n",
      "Current iteration=22, the loss=41959.579593887145\n",
      "Current iteration=23, the loss=41802.582043121314\n",
      "Current iteration=24, the loss=41760.37481418709\n",
      "Current iteration=25, the loss=41752.65150482381\n",
      "Current iteration=26, the loss=41751.58654479045\n",
      "Current iteration=27, the loss=41751.45949462727\n",
      "Current iteration=28, the loss=41751.445273794605\n",
      "Current iteration=29, the loss=41751.44371671363\n",
      "Current iteration=30, the loss=41751.44354789995\n",
      "Current iteration=0, the loss=34780.04607895637\n",
      "Current iteration=1, the loss=34765.54991659192\n",
      "Current iteration=2, the loss=34751.082717225334\n",
      "Current iteration=3, the loss=34736.644392014605\n",
      "Current iteration=4, the loss=34722.23487183194\n",
      "Current iteration=5, the loss=34693.48765737395\n",
      "Current iteration=6, the loss=34650.55984919459\n",
      "Current iteration=7, the loss=34593.691852710625\n",
      "Current iteration=8, the loss=34509.1490086025\n",
      "Current iteration=9, the loss=34384.01891085383\n",
      "Current iteration=10, the loss=34206.80366751064\n",
      "Current iteration=11, the loss=33955.04946501163\n",
      "Current iteration=12, the loss=33599.03243484017\n",
      "Current iteration=13, the loss=33119.741242981\n",
      "Current iteration=14, the loss=32480.539931216703\n",
      "Current iteration=15, the loss=31676.878768496386\n",
      "Current iteration=16, the loss=30716.713161271276\n",
      "Current iteration=17, the loss=29646.746326833225\n",
      "Current iteration=18, the loss=28558.93992530254\n",
      "Current iteration=19, the loss=27571.122447851838\n",
      "Current iteration=20, the loss=26785.84876353054\n",
      "Current iteration=21, the loss=26263.705504976802\n",
      "Current iteration=22, the loss=25993.618084067864\n",
      "Current iteration=23, the loss=25896.289286975072\n",
      "Current iteration=24, the loss=25874.76118083928\n",
      "Current iteration=25, the loss=25872.020873512014\n",
      "Current iteration=26, the loss=25871.7936952989\n",
      "Current iteration=27, the loss=25871.778433479976\n",
      "Current iteration=28, the loss=25871.77747490703\n",
      "Current iteration=0, the loss=15299.837716499673\n",
      "Current iteration=1, the loss=15293.637803590544\n",
      "Current iteration=2, the loss=15287.45028074929\n",
      "Current iteration=3, the loss=15281.27511181715\n",
      "Current iteration=4, the loss=15268.95557887758\n",
      "Current iteration=5, the loss=15250.559113426043\n",
      "Current iteration=6, the loss=15220.111653521873\n",
      "Current iteration=7, the loss=15171.950387149049\n",
      "Current iteration=8, the loss=15095.113115894166\n",
      "Current iteration=9, the loss=14974.620009774428\n",
      "Current iteration=10, the loss=14788.614395154227\n",
      "Current iteration=11, the loss=14509.840287836902\n",
      "Current iteration=12, the loss=14118.973575085474\n",
      "Current iteration=13, the loss=13611.541964392018\n",
      "Current iteration=14, the loss=13027.581981076542\n",
      "Current iteration=15, the loss=12456.32068137628\n",
      "Current iteration=16, the loss=12008.634139804582\n",
      "Current iteration=17, the loss=11754.39300204394\n",
      "Current iteration=18, the loss=11668.843920917388\n",
      "Current iteration=19, the loss=11657.2377522319\n",
      "Current iteration=20, the loss=11656.874907109905\n",
      "Current iteration=21, the loss=11656.872489195961\n",
      "Current iteration=0, the loss=68988.93888113135\n",
      "Current iteration=1, the loss=68943.59645131449\n",
      "Current iteration=2, the loss=68898.34460685114\n",
      "Current iteration=3, the loss=68808.06670666007\n",
      "Current iteration=4, the loss=68673.25663642623\n",
      "Current iteration=5, the loss=68405.6442379955\n",
      "Current iteration=6, the loss=67922.04020157372\n",
      "Current iteration=7, the loss=67065.48989711853\n",
      "Current iteration=8, the loss=65594.43775555425\n",
      "Current iteration=9, the loss=63150.310594788425\n",
      "Current iteration=10, the loss=59407.73394532506\n",
      "Current iteration=11, the loss=54295.677515979245\n",
      "Current iteration=12, the loss=48469.92636331547\n",
      "Current iteration=13, the loss=43258.88031175372\n",
      "Current iteration=14, the loss=39966.82448438266\n",
      "Current iteration=15, the loss=39015.3074786174\n",
      "Current iteration=16, the loss=38945.99793719831\n",
      "Current iteration=17, the loss=38945.44531367696\n",
      "Current iteration=0, the loss=53526.2115772001\n",
      "Current iteration=1, the loss=53506.533614617976\n",
      "Current iteration=2, the loss=53486.89474933365\n",
      "Current iteration=3, the loss=53467.295141291834\n",
      "Current iteration=4, the loss=53447.73464634018\n",
      "Current iteration=5, the loss=53408.71138051359\n",
      "Current iteration=6, the loss=53350.43762605226\n",
      "Current iteration=7, the loss=53273.24016641427\n",
      "Current iteration=8, the loss=53158.475616222415\n",
      "Current iteration=9, the loss=52988.61227068767\n",
      "Current iteration=10, the loss=52748.05204870679\n",
      "Current iteration=11, the loss=52424.13886244328\n",
      "Current iteration=12, the loss=51974.080590752375\n",
      "Current iteration=13, the loss=51351.90625790123\n",
      "Current iteration=14, the loss=50535.1082542729\n",
      "Current iteration=15, the loss=49505.05086729165\n",
      "Current iteration=16, the loss=48279.45324547898\n",
      "Current iteration=17, the loss=46903.1314121801\n",
      "Current iteration=18, the loss=45480.38430056757\n",
      "Current iteration=19, the loss=44158.867943167024\n",
      "Current iteration=20, the loss=43082.08729256909\n",
      "Current iteration=21, the loss=42344.69102103501\n",
      "Current iteration=22, the loss=41946.43682418816\n",
      "Current iteration=23, the loss=41789.17151551462\n",
      "Current iteration=24, the loss=41747.03797747605\n",
      "Current iteration=25, the loss=41739.364228181286\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iteration=26, the loss=41738.311951274816\n",
      "Current iteration=27, the loss=41738.18716743495\n",
      "Current iteration=28, the loss=41738.17328558701\n",
      "Current iteration=29, the loss=41738.171775992865\n",
      "Current iteration=30, the loss=41738.171612228536\n",
      "Current iteration=0, the loss=34776.580343053574\n",
      "Current iteration=1, the loss=34762.09083532861\n",
      "Current iteration=2, the loss=34747.63027726389\n",
      "Current iteration=3, the loss=34733.19859459133\n",
      "Current iteration=4, the loss=34718.79569253164\n",
      "Current iteration=5, the loss=34690.06167273762\n",
      "Current iteration=6, the loss=34647.15357526869\n",
      "Current iteration=7, the loss=34590.311702481835\n",
      "Current iteration=8, the loss=34505.80762891023\n",
      "Current iteration=9, the loss=34380.73494656525\n",
      "Current iteration=10, the loss=34203.601053760045\n",
      "Current iteration=11, the loss=33951.96207164901\n",
      "Current iteration=12, the loss=33596.107812161325\n",
      "Current iteration=13, the loss=33117.034559561704\n",
      "Current iteration=14, the loss=32478.120839237727\n",
      "Current iteration=15, the loss=31674.813377554296\n",
      "Current iteration=16, the loss=30715.054400901576\n",
      "Current iteration=17, the loss=29645.50420108701\n",
      "Current iteration=18, the loss=28558.053997323943\n",
      "Current iteration=19, the loss=27567.476237698716\n",
      "Current iteration=20, the loss=26781.79992967357\n",
      "Current iteration=21, the loss=26260.50117290602\n",
      "Current iteration=22, the loss=25991.504528847054\n",
      "Current iteration=23, the loss=25894.895354044096\n",
      "Current iteration=24, the loss=25873.633002016028\n",
      "Current iteration=25, the loss=25870.945041491843\n",
      "Current iteration=26, the loss=25870.723986951543\n",
      "Current iteration=27, the loss=25870.709258882835\n",
      "Current iteration=28, the loss=25870.708341386395\n",
      "Current iteration=0, the loss=15301.917158041353\n",
      "Current iteration=1, the loss=15295.72156683586\n",
      "Current iteration=2, the loss=15289.538356863173\n",
      "Current iteration=3, the loss=15283.367493249341\n",
      "Current iteration=4, the loss=15271.05655231706\n",
      "Current iteration=5, the loss=15252.672917980966\n",
      "Current iteration=6, the loss=15222.246693879224\n",
      "Current iteration=7, the loss=15174.11902121847\n",
      "Current iteration=8, the loss=15097.335454679847\n",
      "Current iteration=9, the loss=14976.92693122352\n",
      "Current iteration=10, the loss=14791.053332371894\n",
      "Current iteration=11, the loss=14512.482726749531\n",
      "Current iteration=12, the loss=14121.920954257683\n",
      "Current iteration=13, the loss=13614.946484065218\n",
      "Current iteration=14, the loss=13031.67098992386\n",
      "Current iteration=15, the loss=12461.393346388617\n",
      "Current iteration=16, the loss=12014.92209614992\n",
      "Current iteration=17, the loss=11761.7788701256\n",
      "Current iteration=18, the loss=11676.857946789645\n",
      "Current iteration=19, the loss=11665.31876424388\n",
      "Current iteration=20, the loss=11664.95101780185\n",
      "Current iteration=21, the loss=11664.948504877153\n",
      "Current iteration=0, the loss=68959.13355236728\n",
      "Current iteration=1, the loss=68913.8127511758\n",
      "Current iteration=2, the loss=68868.58249256507\n",
      "Current iteration=3, the loss=68778.34765397043\n",
      "Current iteration=4, the loss=68643.60187852495\n",
      "Current iteration=5, the loss=68376.11709634554\n",
      "Current iteration=6, the loss=67892.74363381568\n",
      "Current iteration=7, the loss=67036.60158006003\n",
      "Current iteration=8, the loss=65566.24935140232\n",
      "Current iteration=9, the loss=63123.2787000512\n",
      "Current iteration=10, the loss=59382.44371720556\n",
      "Current iteration=11, the loss=54272.650607103446\n",
      "Current iteration=12, the loss=48449.0908169821\n",
      "Current iteration=13, the loss=43239.048316880486\n",
      "Current iteration=14, the loss=39945.95118548071\n",
      "Current iteration=15, the loss=38992.95254741394\n",
      "Current iteration=16, the loss=38923.35721720847\n",
      "Current iteration=17, the loss=38922.79941892569\n",
      "Current iteration=0, the loss=53542.153962352975\n",
      "Current iteration=1, the loss=53522.49460221367\n",
      "Current iteration=2, the loss=53502.87445611777\n",
      "Current iteration=3, the loss=53483.29332899101\n",
      "Current iteration=4, the loss=53463.751318410665\n",
      "Current iteration=5, the loss=53424.764878998714\n",
      "Current iteration=6, the loss=53366.54633015705\n",
      "Current iteration=7, the loss=53289.4228375198\n",
      "Current iteration=8, the loss=53174.7684232577\n",
      "Current iteration=9, the loss=53005.070739521594\n",
      "Current iteration=10, the loss=52764.73677106482\n",
      "Current iteration=11, the loss=52441.127660338796\n",
      "Current iteration=12, the loss=51991.50707223019\n",
      "Current iteration=13, the loss=51369.93915885128\n",
      "Current iteration=14, the loss=50553.94956841385\n",
      "Current iteration=15, the loss=49524.95247119473\n",
      "Current iteration=16, the loss=48300.72136618068\n",
      "Current iteration=17, the loss=46926.08083956603\n",
      "Current iteration=18, the loss=45505.38515487453\n",
      "Current iteration=19, the loss=44186.26011021432\n",
      "Current iteration=20, the loss=43111.993486939784\n",
      "Current iteration=21, the loss=42376.85588837178\n",
      "Current iteration=22, the loss=41980.185057106835\n",
      "Current iteration=23, the loss=41823.88598350896\n",
      "Current iteration=24, the loss=41781.896515755114\n",
      "Current iteration=25, the loss=41774.21704546406\n",
      "Current iteration=26, the loss=41773.158462018124\n",
      "Current iteration=27, the loss=41773.03219597994\n",
      "Current iteration=28, the loss=41773.01806384122\n",
      "Current iteration=29, the loss=41773.01651649628\n",
      "Current iteration=30, the loss=41773.0163487557\n",
      "Current iteration=0, the loss=34798.06790565093\n",
      "Current iteration=1, the loss=34783.56171747846\n",
      "Current iteration=2, the loss=34769.08451471757\n",
      "Current iteration=3, the loss=34754.63620641813\n",
      "Current iteration=4, the loss=34740.216711811656\n",
      "Current iteration=5, the loss=34711.44959055118\n",
      "Current iteration=6, the loss=34668.49206227154\n",
      "Current iteration=7, the loss=34611.584735504584\n",
      "Current iteration=8, the loss=34526.98334806666\n",
      "Current iteration=9, the loss=34401.766536644354\n",
      "Current iteration=10, the loss=34224.42854601093\n",
      "Current iteration=11, the loss=33972.49962156499\n",
      "Current iteration=12, the loss=33616.23492291845\n",
      "Current iteration=13, the loss=33136.607772836374\n",
      "Current iteration=14, the loss=32496.95283825212\n",
      "Current iteration=15, the loss=31692.70593170851\n",
      "Current iteration=16, the loss=30731.8082565732\n",
      "Current iteration=17, the loss=29660.95931830138\n",
      "Current iteration=18, the loss=28572.141331604136\n",
      "Current iteration=19, the loss=27580.255761785338\n",
      "Current iteration=20, the loss=26793.483977342865\n",
      "Current iteration=21, the loss=26271.432723363927\n",
      "Current iteration=22, the loss=26002.06939019764\n",
      "Current iteration=23, the loss=25905.2709835296\n",
      "Current iteration=24, the loss=25884.06316782491\n",
      "Current iteration=25, the loss=25881.399306298154\n",
      "Current iteration=26, the loss=25881.18205542942\n",
      "Current iteration=27, the loss=25881.167587827716\n",
      "Current iteration=28, the loss=25881.16668667604\n",
      "Current iteration=0, the loss=15294.292539055194\n",
      "Current iteration=1, the loss=15288.090498595062\n",
      "Current iteration=2, the loss=15281.900851881863\n",
      "Current iteration=3, the loss=15275.723563343965\n",
      "Current iteration=4, the loss=15263.399802165644\n",
      "Current iteration=5, the loss=15244.997024981076\n",
      "Current iteration=6, the loss=15214.5391171169\n",
      "Current iteration=7, the loss=15166.361326537995\n",
      "Current iteration=8, the loss=15089.497726764115\n",
      "Current iteration=9, the loss=14968.963434983354\n",
      "Current iteration=10, the loss=14782.894585834214\n",
      "Current iteration=11, the loss=14504.02736354003\n",
      "Current iteration=12, the loss=14113.035445160825\n",
      "Current iteration=13, the loss=13605.457713325472\n",
      "Current iteration=14, the loss=13021.370489457619\n",
      "Current iteration=15, the loss=12450.059938359384\n",
      "Current iteration=16, the loss=12002.42956343228\n",
      "Current iteration=17, the loss=11748.011387055169\n",
      "Current iteration=18, the loss=11662.724791257824\n",
      "Current iteration=19, the loss=11651.233051835878\n",
      "Current iteration=20, the loss=11650.874890195766\n",
      "Current iteration=21, the loss=11650.872507858374\n",
      "Current iteration=0, the loss=68972.30334879791\n",
      "Current iteration=1, the loss=68926.97105693592\n",
      "Current iteration=2, the loss=68881.72933129969\n",
      "Current iteration=3, the loss=68791.47162805725\n",
      "Current iteration=4, the loss=68656.69170059761\n",
      "Current iteration=5, the loss=68389.13915789062\n",
      "Current iteration=6, the loss=67905.6432867446\n",
      "Current iteration=7, the loss=67049.28429265518\n",
      "Current iteration=8, the loss=65578.55940622861\n",
      "Current iteration=9, the loss=63134.969984081225\n",
      "Current iteration=10, the loss=59393.19038197185\n",
      "Current iteration=11, the loss=54282.12961534274\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iteration=12, the loss=48457.25141036411\n",
      "Current iteration=13, the loss=43246.52849434658\n",
      "Current iteration=14, the loss=39954.28570195004\n",
      "Current iteration=15, the loss=39002.60127369778\n",
      "Current iteration=16, the loss=38933.25605651912\n",
      "Current iteration=17, the loss=38932.702655181994\n",
      "Current iteration=0, the loss=53532.44990182514\n",
      "Current iteration=1, the loss=53512.781232045076\n",
      "Current iteration=2, the loss=53493.15169423484\n",
      "Current iteration=3, the loss=53473.56127886527\n",
      "Current iteration=4, the loss=53454.01036682841\n",
      "Current iteration=5, the loss=53415.0060258811\n",
      "Current iteration=6, the loss=53356.75968293351\n",
      "Current iteration=7, the loss=53279.59928803463\n",
      "Current iteration=8, the loss=53164.890147470665\n",
      "Current iteration=9, the loss=52995.11305772573\n",
      "Current iteration=10, the loss=52754.66915844956\n",
      "Current iteration=11, the loss=52430.90777388029\n",
      "Current iteration=12, the loss=51981.069431489086\n",
      "Current iteration=13, the loss=51359.208539947045\n",
      "Current iteration=14, the loss=50542.82677618679\n",
      "Current iteration=15, the loss=49513.33171500056\n",
      "Current iteration=16, the loss=48277.44618490116\n",
      "Current iteration=17, the loss=46895.61426815313\n",
      "Current iteration=18, the loss=45472.22405054967\n",
      "Current iteration=19, the loss=44154.13123947122\n",
      "Current iteration=20, the loss=43083.279620121306\n",
      "Current iteration=21, the loss=42352.28185294904\n",
      "Current iteration=22, the loss=41958.45773454064\n",
      "Current iteration=23, the loss=41804.374291651264\n",
      "Current iteration=24, the loss=41763.362265327756\n",
      "Current iteration=25, the loss=41755.95196599298\n",
      "Current iteration=26, the loss=41754.93684477808\n",
      "Current iteration=27, the loss=41754.817340380905\n",
      "Current iteration=28, the loss=41754.804049490864\n",
      "Current iteration=29, the loss=41754.80260319836\n",
      "Current iteration=30, the loss=41754.802447364724\n",
      "Current iteration=0, the loss=34784.898109220296\n",
      "Current iteration=1, the loss=34770.391924853924\n",
      "Current iteration=2, the loss=34755.914724656475\n",
      "Current iteration=3, the loss=34741.46643061173\n",
      "Current iteration=4, the loss=34727.046957301936\n",
      "Current iteration=5, the loss=34698.27986548295\n",
      "Current iteration=6, the loss=34655.322362679675\n",
      "Current iteration=7, the loss=34598.41507351316\n",
      "Current iteration=8, the loss=34513.81377423207\n",
      "Current iteration=9, the loss=34388.59716227255\n",
      "Current iteration=10, the loss=34211.25938229198\n",
      "Current iteration=11, the loss=33959.33076636747\n",
      "Current iteration=12, the loss=33603.066856611935\n",
      "Current iteration=13, the loss=33123.44161508762\n",
      "Current iteration=14, the loss=32483.79070165725\n",
      "Current iteration=15, the loss=31679.554031501797\n",
      "Current iteration=16, the loss=30718.679486522586\n",
      "Current iteration=17, the loss=29647.88171963505\n",
      "Current iteration=18, the loss=28559.167919830325\n",
      "Current iteration=19, the loss=27570.455054900267\n",
      "Current iteration=20, the loss=26784.426729750605\n",
      "Current iteration=21, the loss=26261.80279431513\n",
      "Current iteration=22, the loss=25991.537689528228\n",
      "Current iteration=23, the loss=25894.198166482103\n",
      "Current iteration=24, the loss=25872.681946739467\n",
      "Current iteration=25, the loss=25869.944524912276\n",
      "Current iteration=26, the loss=25869.717640410057\n",
      "Current iteration=27, the loss=25869.702399514368\n",
      "Current iteration=28, the loss=25869.7014422788\n",
      "Current iteration=0, the loss=15303.996599583032\n",
      "Current iteration=1, the loss=15297.789628754954\n",
      "Current iteration=2, the loss=15291.595060559015\n",
      "Current iteration=3, the loss=15285.412860661818\n",
      "Current iteration=4, the loss=15273.07930458012\n",
      "Current iteration=5, the loss=15254.66189859188\n",
      "Current iteration=6, the loss=15224.179779687984\n",
      "Current iteration=7, the loss=15175.963684685797\n",
      "Current iteration=8, the loss=15099.038947674442\n",
      "Current iteration=9, the loss=14978.408745154278\n",
      "Current iteration=10, the loss=14792.191699558396\n",
      "Current iteration=11, the loss=14513.101566579917\n",
      "Current iteration=12, the loss=14121.794517518476\n",
      "Current iteration=13, the loss=13613.799705808628\n",
      "Current iteration=14, the loss=13029.211010475343\n",
      "Current iteration=15, the loss=12457.363532194486\n",
      "Current iteration=16, the loss=12009.235122685403\n",
      "Current iteration=17, the loss=11754.730072113589\n",
      "Current iteration=18, the loss=11669.071552231084\n",
      "Current iteration=19, the loss=11657.44867945469\n",
      "Current iteration=20, the loss=11657.081124256703\n",
      "Current iteration=21, the loss=11657.078611285184\n",
      "Current iteration=0, the loss=68972.30334879791\n",
      "Current iteration=1, the loss=68926.98268379789\n",
      "Current iteration=2, the loss=68881.75256159443\n",
      "Current iteration=3, the loss=68791.51800093525\n",
      "Current iteration=4, the loss=68656.77263791955\n",
      "Current iteration=5, the loss=68389.28873262642\n",
      "Current iteration=6, the loss=67905.91688047242\n",
      "Current iteration=7, the loss=67049.77814869891\n",
      "Current iteration=8, the loss=65579.4344252502\n",
      "Current iteration=9, the loss=63136.492594399686\n",
      "Current iteration=10, the loss=59395.7736424804\n",
      "Current iteration=11, the loss=54286.42450367703\n",
      "Current iteration=12, the loss=48464.15946566184\n",
      "Current iteration=13, the loss=43256.58217600416\n",
      "Current iteration=14, the loss=39966.35313036409\n",
      "Current iteration=15, the loss=39014.84860885672\n",
      "Current iteration=16, the loss=38945.45670216877\n",
      "Current iteration=17, the loss=38944.90222190033\n",
      "Current iteration=0, the loss=53519.2801053945\n",
      "Current iteration=1, the loss=53499.62306629512\n",
      "Current iteration=2, the loss=53480.005361489995\n",
      "Current iteration=3, the loss=53460.42682472525\n",
      "Current iteration=4, the loss=53440.887389798\n",
      "Current iteration=5, the loss=53401.90572404454\n",
      "Current iteration=6, the loss=53343.69488832203\n",
      "Current iteration=7, the loss=53266.5819674632\n",
      "Current iteration=8, the loss=53151.94104064642\n",
      "Current iteration=9, the loss=52982.26435176841\n",
      "Current iteration=10, the loss=52741.966443338264\n",
      "Current iteration=11, the loss=52418.40126741376\n",
      "Current iteration=12, the loss=51968.83011865986\n",
      "Current iteration=13, the loss=51347.33371038694\n",
      "Current iteration=14, the loss=50531.44153804627\n",
      "Current iteration=15, the loss=49502.52408493755\n",
      "Current iteration=16, the loss=48278.33288642549\n",
      "Current iteration=17, the loss=46903.63715116951\n",
      "Current iteration=18, the loss=45482.65989313695\n",
      "Current iteration=19, the loss=44162.96976690794\n",
      "Current iteration=20, the loss=43087.86520681423\n",
      "Current iteration=21, the loss=42351.8235853719\n",
      "Current iteration=22, the loss=41954.43995136785\n",
      "Current iteration=23, the loss=41797.58807480887\n",
      "Current iteration=24, the loss=41755.62251172486\n",
      "Current iteration=25, the loss=41747.94661707697\n",
      "Current iteration=26, the loss=41746.887702254644\n",
      "Current iteration=27, the loss=41746.762212875605\n",
      "Current iteration=28, the loss=41746.7481684111\n",
      "Current iteration=29, the loss=41746.746630635906\n",
      "Current iteration=30, the loss=41746.74646392778\n",
      "Current iteration=0, the loss=34800.147347192615\n",
      "Current iteration=1, the loss=34785.64228070888\n",
      "Current iteration=2, the loss=34771.16619818062\n",
      "Current iteration=3, the loss=34756.71901305303\n",
      "Current iteration=4, the loss=34742.30064435481\n",
      "Current iteration=5, the loss=34713.535758542865\n",
      "Current iteration=6, the loss=34670.581550805095\n",
      "Current iteration=7, the loss=34613.67864272225\n",
      "Current iteration=8, the loss=34529.083857221616\n",
      "Current iteration=9, the loss=34403.876879068266\n",
      "Current iteration=10, the loss=34226.55296323908\n",
      "Current iteration=11, the loss=33974.64401247554\n",
      "Current iteration=12, the loss=33618.40825668047\n",
      "Current iteration=13, the loss=33138.8224403403\n",
      "Current iteration=14, the loss=32499.227439251365\n",
      "Current iteration=15, the loss=31695.07045540275\n",
      "Current iteration=16, the loss=30734.3101074837\n",
      "Current iteration=17, the loss=29663.674100763303\n",
      "Current iteration=18, the loss=28575.170164362098\n",
      "Current iteration=19, the loss=27583.700612821256\n",
      "Current iteration=20, the loss=26797.38862937446\n",
      "Current iteration=21, the loss=26275.727006667275\n",
      "Current iteration=22, the loss=26006.57711540532\n",
      "Current iteration=23, the loss=25909.924275153466\n",
      "Current iteration=24, the loss=25888.65361010067\n",
      "Current iteration=25, the loss=25885.964602710323\n",
      "Current iteration=26, the loss=25885.743458959594\n",
      "Current iteration=27, the loss=25885.728724798\n",
      "Current iteration=28, the loss=25885.72780692002\n",
      "Current iteration=0, the loss=15301.917158041353\n",
      "Current iteration=1, the loss=15295.71630202047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iteration=2, the loss=15289.527835819048\n",
      "Current iteration=3, the loss=15283.351727713845\n",
      "Current iteration=4, the loss=15271.03032330082\n",
      "Current iteration=5, the loss=15252.631060700965\n",
      "Current iteration=6, the loss=15222.178979831593\n",
      "Current iteration=7, the loss=15174.010385565683\n",
      "Current iteration=8, the loss=15097.16146210731\n",
      "Current iteration=9, the loss=14976.650271020571\n",
      "Current iteration=10, the loss=14790.61725700718\n",
      "Current iteration=11, the loss=14511.80432141295\n",
      "Current iteration=12, the loss=14120.890646970201\n",
      "Current iteration=13, the loss=13613.421761768957\n",
      "Current iteration=14, the loss=13029.48023819069\n",
      "Current iteration=15, the loss=12458.356161782947\n",
      "Current iteration=16, the loss=12010.935816752295\n",
      "Current iteration=17, the loss=11756.978170472514\n",
      "Current iteration=18, the loss=11671.642488004025\n",
      "Current iteration=19, the loss=11660.020832590548\n",
      "Current iteration=20, the loss=11659.64951065327\n",
      "Current iteration=21, the loss=11659.64696975649\n",
      "Current iteration=0, the loss=68979.23482060351\n",
      "Current iteration=1, the loss=68933.88872356794\n",
      "Current iteration=2, the loss=68888.63322110301\n",
      "Current iteration=3, the loss=68798.3480204383\n",
      "Current iteration=4, the loss=68663.52702935743\n",
      "Current iteration=5, the loss=68395.89297192395\n",
      "Current iteration=6, the loss=67912.24975520415\n",
      "Current iteration=7, the loss=67055.62973808404\n",
      "Current iteration=8, the loss=65584.4564647867\n",
      "Current iteration=9, the loss=63140.12025624422\n",
      "Current iteration=10, the loss=59397.191528049494\n",
      "Current iteration=11, the loss=54284.55866215146\n",
      "Current iteration=12, the loss=48457.93720081031\n",
      "Current iteration=13, the loss=43238.77431155642\n",
      "Current iteration=14, the loss=39948.62033698487\n",
      "Current iteration=15, the loss=39000.756045021364\n",
      "Current iteration=16, the loss=38931.907707685896\n",
      "Current iteration=17, the loss=38931.36191452357\n",
      "Current iteration=0, the loss=53542.84710953353\n",
      "Current iteration=1, the loss=53523.176592653006\n",
      "Current iteration=2, the loss=53503.54553575969\n",
      "Current iteration=3, the loss=53483.95379336899\n",
      "Current iteration=4, the loss=53464.401057981304\n",
      "Current iteration=5, the loss=53425.393777081896\n",
      "Current iteration=6, the loss=53367.14397761699\n",
      "Current iteration=7, the loss=53289.97721904921\n",
      "Current iteration=8, the loss=53175.259194233804\n",
      "Current iteration=9, the loss=53005.465683352224\n",
      "Current iteration=10, the loss=52764.999899231465\n",
      "Current iteration=11, the loss=52441.21233467065\n",
      "Current iteration=12, the loss=51991.33661194385\n",
      "Current iteration=13, the loss=51369.41818080119\n",
      "Current iteration=14, the loss=50552.98059989216\n",
      "Current iteration=15, the loss=49523.426958245764\n",
      "Current iteration=16, the loss=48287.482720171676\n",
      "Current iteration=17, the loss=46905.604204618074\n",
      "Current iteration=18, the loss=45482.259874434356\n",
      "Current iteration=19, the loss=44164.313355420796\n",
      "Current iteration=20, the loss=43093.684107980334\n",
      "Current iteration=21, the loss=42362.93637408329\n",
      "Current iteration=22, the loss=41969.30709549951\n",
      "Current iteration=23, the loss=41815.32640695255\n",
      "Current iteration=24, the loss=41774.38605710834\n",
      "Current iteration=25, the loss=41766.94963246293\n",
      "Current iteration=26, the loss=41765.9315267213\n",
      "Current iteration=27, the loss=41765.81087945457\n",
      "Current iteration=28, the loss=41765.79746094663\n",
      "Current iteration=29, the loss=41765.79600181342\n",
      "Current iteration=30, the loss=41765.79584352561\n",
      "Current iteration=0, the loss=34775.887195873016\n",
      "Current iteration=1, the loss=34761.37111833168\n",
      "Current iteration=2, the loss=34746.884036769065\n",
      "Current iteration=3, the loss=34732.42587747069\n",
      "Current iteration=4, the loss=34717.99655873029\n",
      "Current iteration=5, the loss=34689.209822654186\n",
      "Current iteration=6, the loss=34646.2230106772\n",
      "Current iteration=7, the loss=34589.27686597116\n",
      "Current iteration=8, the loss=34504.617867518704\n",
      "Current iteration=9, the loss=34379.3157760143\n",
      "Current iteration=10, the loss=34201.85719256302\n",
      "Current iteration=11, the loss=33949.75685304515\n",
      "Current iteration=12, the loss=33593.250163835815\n",
      "Current iteration=13, the loss=33113.29872224627\n",
      "Current iteration=14, the loss=32473.215131804172\n",
      "Current iteration=15, the loss=31668.43938827635\n",
      "Current iteration=16, the loss=30706.931753570054\n",
      "Current iteration=17, the loss=29635.44940428631\n",
      "Current iteration=18, the loss=28546.072343987442\n",
      "Current iteration=19, the loss=27553.82340243567\n",
      "Current iteration=20, the loss=26766.980103223315\n",
      "Current iteration=21, the loss=26245.142069833044\n",
      "Current iteration=22, the loss=25976.102504643877\n",
      "Current iteration=23, the loss=25879.52030526945\n",
      "Current iteration=24, the loss=25858.397198190432\n",
      "Current iteration=25, the loss=25855.73173314768\n",
      "Current iteration=26, the loss=25855.512746782806\n",
      "Current iteration=27, the loss=25855.498161594493\n",
      "Current iteration=28, the loss=25855.497253086258\n",
      "Current iteration=0, the loss=15295.678833416312\n",
      "Current iteration=1, the loss=15289.476573128812\n",
      "Current iteration=2, the loss=15283.286705152299\n",
      "Current iteration=3, the loss=15277.109198283903\n",
      "Current iteration=4, the loss=15264.785002875027\n",
      "Current iteration=5, the loss=15246.381574276706\n",
      "Current iteration=6, the loss=15215.922588806512\n",
      "Current iteration=7, the loss=15167.74310695193\n",
      "Current iteration=8, the loss=15090.876818859431\n",
      "Current iteration=9, the loss=14970.338469587678\n",
      "Current iteration=10, the loss=14784.263915396514\n",
      "Current iteration=11, the loss=14505.390146230664\n",
      "Current iteration=12, the loss=14114.396134985542\n",
      "Current iteration=13, the loss=13606.837903398995\n",
      "Current iteration=14, the loss=13022.829014509265\n",
      "Current iteration=15, the loss=12451.703055445756\n",
      "Current iteration=16, the loss=12003.574922199377\n",
      "Current iteration=17, the loss=11749.712285651589\n",
      "Current iteration=18, the loss=11664.975910322737\n",
      "Current iteration=19, the loss=11653.63903974621\n",
      "Current iteration=20, the loss=11653.290791681882\n",
      "Current iteration=21, the loss=11653.288482387823\n",
      "Current iteration=0, the loss=68994.48405857584\n",
      "Current iteration=1, the loss=68949.13416135084\n",
      "Current iteration=2, the loss=68903.87486903912\n",
      "Current iteration=3, the loss=68813.58210007005\n",
      "Current iteration=4, the loss=68678.74983016046\n",
      "Current iteration=5, the loss=68411.09337640072\n",
      "Current iteration=6, the loss=67927.40984831753\n",
      "Current iteration=7, the loss=67070.71942391066\n",
      "Current iteration=8, the loss=65599.43033955446\n",
      "Current iteration=9, the loss=63154.928537558306\n",
      "Current iteration=10, the loss=59411.85844689116\n",
      "Current iteration=11, the loss=54299.35561918783\n",
      "Current iteration=12, the loss=48473.41301198956\n",
      "Current iteration=13, the loss=43262.36780122941\n",
      "Current iteration=14, the loss=39970.444014145476\n",
      "Current iteration=15, the loss=39019.02812315811\n",
      "Current iteration=16, the loss=38949.71058265688\n",
      "Current iteration=17, the loss=38949.15738721293\n",
      "Current iteration=0, the loss=53537.30193208905\n",
      "Current iteration=1, the loss=53517.647732883685\n",
      "Current iteration=2, the loss=53498.032724312754\n",
      "Current iteration=3, the loss=53478.4567646433\n",
      "Current iteration=4, the loss=53458.92004744392\n",
      "Current iteration=5, the loss=53419.94348005003\n",
      "Current iteration=6, the loss=53361.741407980735\n",
      "Current iteration=7, the loss=53284.63902804648\n",
      "Current iteration=8, the loss=53170.01285964481\n",
      "Current iteration=9, the loss=53000.36238965795\n",
      "Current iteration=10, the loss=52760.093240419075\n",
      "Current iteration=11, the loss=52436.56905990791\n",
      "Current iteration=12, the loss=51987.06580816818\n",
      "Current iteration=13, the loss=51365.66097715572\n",
      "Current iteration=14, the loss=50549.88814341143\n",
      "Current iteration=15, the loss=49521.167492148146\n",
      "Current iteration=16, the loss=48286.22143608796\n",
      "Current iteration=17, the loss=46905.48748840357\n",
      "Current iteration=18, the loss=45483.25476612002\n",
      "Current iteration=19, the loss=44166.32490921914\n",
      "Current iteration=20, the loss=43096.49325605721\n",
      "Current iteration=21, the loss=42366.268356346096\n",
      "Current iteration=22, the loss=41972.88116799999\n",
      "Current iteration=23, the loss=41818.98325953125\n",
      "Current iteration=24, the loss=41778.06189923968\n",
      "Current iteration=25, the loss=41770.62851482657\n",
      "Current iteration=26, the loss=41769.610828937235\n",
      "Current iteration=27, the loss=41769.490228028015\n",
      "Current iteration=28, the loss=41769.476814681446\n",
      "Current iteration=29, the loss=41769.47535612145\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iteration=30, the loss=41769.4751980101\n",
      "Current iteration=0, the loss=34768.95572406741\n",
      "Current iteration=1, the loss=34754.4325338433\n",
      "Current iteration=2, the loss=34739.9383578845\n",
      "Current iteration=3, the loss=34725.473121914525\n",
      "Current iteration=4, the loss=34711.03673125608\n",
      "Current iteration=5, the loss=34682.23591469806\n",
      "Current iteration=6, the loss=34639.228065789925\n",
      "Current iteration=7, the loss=34582.25401185723\n",
      "Current iteration=8, the loss=34497.55350590008\n",
      "Current iteration=9, the loss=34372.19003998098\n",
      "Current iteration=10, the loss=34194.644401547564\n",
      "Current iteration=11, the loss=33942.42062585909\n",
      "Current iteration=12, the loss=33585.7399247603\n",
      "Current iteration=13, the loss=33105.55473763901\n",
      "Current iteration=14, the loss=32465.161399244753\n",
      "Current iteration=15, the loss=31660.001442330537\n",
      "Current iteration=16, the loss=30698.046321118665\n",
      "Current iteration=17, the loss=29626.086971557634\n",
      "Current iteration=18, the loss=28536.25874247826\n",
      "Current iteration=19, the loss=27543.625552839545\n",
      "Current iteration=20, the loss=26756.45744962695\n",
      "Current iteration=21, the loss=26234.303591429412\n",
      "Current iteration=22, the loss=25964.952084980956\n",
      "Current iteration=23, the loss=25868.15241404779\n",
      "Current iteration=24, the loss=25846.93397377395\n",
      "Current iteration=25, the loss=25844.267028024657\n",
      "Current iteration=26, the loss=25844.04943262104\n",
      "Current iteration=27, the loss=25844.03493979421\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-9686d02fe576>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogistic_cross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk_fold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m250\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/vinz/Desktop/MachineLearning-Project1/implementations.py\u001b[0m in \u001b[0;36mlogistic_cross_validation\u001b[0;34m(y, x, k_fold, seed)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk_fold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m         \u001b[0mtmp_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_validation_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m         \u001b[0maccuracy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_accuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/vinz/Desktop/MachineLearning-Project1/implementations.py\u001b[0m in \u001b[0;36mcross_validation_step\u001b[0;34m(k)\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_predict_logistic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0msum_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtest_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/vinz/Desktop/MachineLearning-Project1/implementations.py\u001b[0m in \u001b[0;36mtrain_predict_logistic\u001b[0;34m(y_train, x_train, x_test)\u001b[0m\n\u001b[1;32m    131\u001b[0m                                          \u001b[0mx_train_cat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m                                          \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m                                          threshold=10**(-4))\n\u001b[0m\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0mcat_indices_te\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcat_col\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/vinz/Desktop/MachineLearning-Project1/implementations.py\u001b[0m in \u001b[0;36mlogistic_regression\u001b[0;34m(y, tx_data, max_iter, threshold, lambda_)\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0mprev_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m         \u001b[0mnext_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnewton_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    262\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprev_loss\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnext_loss\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/vinz/Desktop/MachineLearning-Project1/implementations.py\u001b[0m in \u001b[0;36mnewton_step\u001b[0;34m(y, tx, w)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0mregularizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlambda_\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlambda_\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m         \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0marmijo_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhess\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mgrad\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mregularizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/vinz/Desktop/MachineLearning-Project1/implementations.py\u001b[0m in \u001b[0;36marmijo_step\u001b[0;34m(grad, w, tx, tests)\u001b[0m\n\u001b[1;32m    238\u001b[0m         \u001b[0metas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtests\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# Learning rates to test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0;31m# Compute for each learning rate, the \"length\" of move, to minimize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtx\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtests\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mouter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0metas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# Take etas that minimizes phi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/vinz/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36mnorm\u001b[0;34m(x, ord, axis, keepdims)\u001b[0m\n\u001b[1;32m   2203\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mord\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mord\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2204\u001b[0m             \u001b[0;31m# special case for speedup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2205\u001b[0;31m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2206\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeepdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2207\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start = time.perf_counter()\n",
    "accuracy = imp.logistic_cross_validation(y_train, x_train, k_fold=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iteration=0, the loss=69254.41425128581\n",
      "Current iteration=1, the loss=69208.90428501768\n",
      "Current iteration=2, the loss=69163.4852396406\n",
      "Current iteration=3, the loss=69072.873775137\n",
      "Current iteration=4, the loss=68937.56558806098\n",
      "Current iteration=5, the loss=68668.96439712941\n",
      "Current iteration=6, the loss=68183.5734886181\n",
      "Current iteration=7, the loss=67323.85835125927\n",
      "Current iteration=8, the loss=65847.37097946732\n",
      "Current iteration=9, the loss=63394.21364480965\n",
      "Current iteration=10, the loss=59637.81539444657\n",
      "Current iteration=11, the loss=54506.90721253042\n",
      "Current iteration=12, the loss=48659.72626655982\n",
      "Current iteration=13, the loss=43429.53963627368\n",
      "Current iteration=14, the loss=40125.343566794705\n",
      "Current iteration=15, the loss=39170.31738645596\n",
      "Current iteration=16, the loss=39100.765210241785\n",
      "Current iteration=17, the loss=39100.21091886141\n",
      "Current iteration=0, the loss=53749.4049693404\n",
      "Current iteration=1, the loss=53729.664765810565\n",
      "Current iteration=2, the loss=53709.963914572\n",
      "Current iteration=3, the loss=53690.302526258514\n",
      "Current iteration=4, the loss=53670.680188387145\n",
      "Current iteration=5, the loss=53631.5338538717\n",
      "Current iteration=6, the loss=53573.07727669725\n",
      "Current iteration=7, the loss=53495.63700765071\n",
      "Current iteration=8, the loss=53380.50908593281\n",
      "Current iteration=9, the loss=53210.11304377393\n",
      "Current iteration=10, the loss=52968.79467051636\n",
      "Current iteration=11, the loss=52643.85882151263\n",
      "Current iteration=12, the loss=52192.385839830604\n",
      "Current iteration=13, the loss=51568.24929754849\n",
      "Current iteration=14, the loss=50748.90028285849\n",
      "Current iteration=15, the loss=49715.647529242175\n",
      "Current iteration=16, the loss=48475.24775925407\n",
      "Current iteration=17, the loss=47088.35871200191\n",
      "Current iteration=18, the loss=45659.72758740147\n",
      "Current iteration=19, the loss=44336.73863839816\n",
      "Current iteration=20, the loss=43261.880604685524\n",
      "Current iteration=21, the loss=42528.10500457806\n",
      "Current iteration=22, the loss=42132.75933255728\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-c6776d21488a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperf_counter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_predict_logistic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperf_counter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/vinz/Desktop/MachineLearning-Project1/implementations.py\u001b[0m in \u001b[0;36mtrain_predict_logistic\u001b[0;34m(y_train, x_train, x_test)\u001b[0m\n\u001b[1;32m    131\u001b[0m                                          \u001b[0mx_train_cat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m                                          \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m                                          threshold=10**(-4))\n\u001b[0m\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0mcat_indices_te\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcat_col\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/vinz/Desktop/MachineLearning-Project1/implementations.py\u001b[0m in \u001b[0;36mlogistic_regression\u001b[0;34m(y, tx_data, max_iter, threshold, lambda_)\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0mprev_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m         \u001b[0mnext_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnewton_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    262\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprev_loss\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnext_loss\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/vinz/Desktop/MachineLearning-Project1/implementations.py\u001b[0m in \u001b[0;36mnewton_step\u001b[0;34m(y, tx, w)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0mregularizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlambda_\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlambda_\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m         \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0marmijo_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhess\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mgrad\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mregularizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/vinz/Desktop/MachineLearning-Project1/implementations.py\u001b[0m in \u001b[0;36marmijo_step\u001b[0;34m(grad, w, tx, tests)\u001b[0m\n\u001b[1;32m    238\u001b[0m         \u001b[0metas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtests\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# Learning rates to test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0;31m# Compute for each learning rate, the \"length\" of move, to minimize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtx\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtests\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mouter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0metas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# Take etas that minimizes phi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/vinz/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36mnorm\u001b[0;34m(x, ord, axis, keepdims)\u001b[0m\n\u001b[1;32m   2203\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mord\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mord\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2204\u001b[0m             \u001b[0;31m# special case for speedup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2205\u001b[0;31m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2206\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeepdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2207\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start = time.perf_counter()\n",
    "preds = imp.train_predict_logistic(y_train, x_train, x_test)\n",
    "end = time.perf_counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "helper.create_csv_submission(ids_test, preds, 'separated2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "niter = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start = time.perf_counter()\n",
    "l, w, data = imp.stochastic_logistic_regression(y_train, std_x_train, max_iter=niter, batch_size=150, threshold=10**(-4))\n",
    "end = time.perf_counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Runtime:\", end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(data[100:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Loss first iteration\", data[0])\n",
    "print(\"Loss iteration at iteration\", niter, data[-1])\n",
    "print(\"delta of losses\", data[0] - data[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "std_x_test = np.hstack((np.ones((std_x_test.shape[0], 1)), std_x_test))                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = helper.predict_labels(w, std_x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "helper.create_csv_submission(ids_test, predictions, 'newton.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raw least squares (score: ?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(w, loss) = imp.least_squares(y_train, x_train)\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Std least squares (score: 0.73)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(w, loss) = imp.least_squares(y_train, col_std_x_train)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(w, loss) = imp.least_squares(y_train, std_x_train)\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eigenvalues reduction (score: 0.62)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = np.matrix([[1,2],[3,4]])\n",
    "np.tile(a, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "std_x_train = standardize(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "u, s, v = np.linalg.svd(std_x_train, full_matrices=False)\n",
    "print('u shape:', u.shape)\n",
    "print('s shape:', s.shape)\n",
    "print('v shape:', v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(s)\n",
    "plt.yscale('log')\n",
    "plt.title('log')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shortened_x_train = u[:, :23] @ np.diag(s[:23]) @ v[:23,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shortened_x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(w, loss) = imp.least_squares(y_train, x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = helper.predict_labels(w, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Number of boson:', np.count_nonzero(y_pred+1))\n",
    "print('Number of other:', np.count_nonzero(y_pred-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "helper.create_csv_submission(ids_test, y_pred, 'shortened_eigenvalues_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unique_values_per_column_count = [len(set(col)) for col in train_data.T]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unique_values_per_column_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def y_map(y):\n",
    "    if y == -1:\n",
    "        return 0\n",
    "    else:\n",
    "        return 0.2\n",
    "\n",
    "y_train_mapped = np.vectorize(y_map)(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "square_train_data = std_x_train.T @ std_x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w, v = np.linalg.eigh(square_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(w.shape[0])\n",
    "print(v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def keep_variance(percentage, vec):\n",
    "    r = list(range(1, w.shape[0] + 1))\n",
    "    total = np.sum(vec)\n",
    "    sums = list(map(lambda i: np.sum(vec[-i:]), r))\n",
    "    ratio = sums / total\n",
    "    return np.argmin(abs(ratio - percentage)) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "index_keeper = keep_variance(0.9, w)\n",
    "print(index_keeper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(w)\n",
    "plt.yscale('log')\n",
    "plt.title('log')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filtered_v = v[:,-index_keeper:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filtered_v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "project_x_train = std_x_train @ filtered_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tupled_boson = np.array(list(zip(*filter(lambda pair: pair[1] == -1, zip(project_x_train.tolist(), y_train))))[0])\n",
    "tupled_other = np.array(list(zip(*filter(lambda pair: pair[1] == 1, zip(project_x_train.tolist(), y_train))))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tupled_boson.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(tupled_boson[1000:2000, :1], tupled_boson[1000:2000, 1:], 'bo')\n",
    "plt.plot(tupled_other[1000:2000, :1], tupled_other[1000:2000, 1:], 'ro')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(weight, loss) = imp.least_squares(y_train, project_x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = helper.predict_labels(weight, std_x_test @ filtered_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Number of boson:', np.count_nonzero(y_pred+1))\n",
    "print('Number of other:', np.count_nonzero(y_pred-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Polynomial feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.array(range(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def polynomial_enhancement(x, deg):\n",
    "    stacked_x = np.tile(x, deg+1)\n",
    "    power_vec = np.repeat(np.array(range(deg+1)), x.shape[1])\n",
    "    return stacked_x ** power_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "enhanced_col_std_x_train = polynomial_enhancement(std_x_train, 9)\n",
    "enhanced_col_std_x_test = polynomial_enhancement(std_x_test, 9)\n",
    "enhanced_col_std_x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pseudo_least_squares(y, x):\n",
    "    U, S, V = np.linalg.svd(x, full_matrices=False)\n",
    "    w = V.T @ np.diag(1/S) @ U.T @ y\n",
    "    loss = imp.mse(y, x, w)\n",
    "    return (w, loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(w, loss) = pseudo_least_squares(y_train, enhanced_col_std_x_train)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = helper.predict_labels(w, enhanced_col_std_x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "helper.create_csv_submission(ids_test, y_pred, 'basic_poly_enhancement_9.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "acc, loss_train, loss_test, w = imp.cross_validation_v2(y_train, std_x_train, 10, imp.pseudo_least_squares, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "enhanced_col_std_x_test = imp.polynomial_enhancement(std_x_test, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = helper.predict_labels(w, enhanced_col_std_x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "helper.create_csv_submission(ids_test, y_pred, '0_8_accuracy_poly_5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = []\n",
    "\n",
    "test.append(1)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "acc, loss_train, loss_test, w = imp.cross_validation_v2(y_train, std_x_train, 10, imp.pseudo_least_squares, 5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
