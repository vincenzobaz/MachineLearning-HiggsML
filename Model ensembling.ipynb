{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import scripts.proj1_helpers as helper\n",
    "import run as run\n",
    "import implementations as imp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import logistic as logistic\n",
    "import minimizers\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def special_preprocess(x_tr, x_test, deg_der=1, deg_pri=1, deg_cat=1):\n",
    "    x = x_tr.copy()\n",
    "    stds = np.std(x, axis=0)\n",
    "    deleted_cols_ids = np.where(stds == 0)\n",
    "    x = np.delete(x, deleted_cols_ids, axis=1)\n",
    "    run.mean_spec(x)\n",
    "    x = run.standardize(x)\n",
    "    #x = special_poly_enhancement(x, deg_der, deg_pri, deg_cat)\n",
    "    #x = np.hstack((np.ones((x.shape[0], 1)), x))\n",
    "    x = run.polynomial_enhancement(x, deg_der)\n",
    "    \n",
    "    x_te = x_test.copy()\n",
    "    x_te = np.delete(x_te, deleted_cols_ids, axis=1)\n",
    "    run.mean_spec(x_te)\n",
    "    x_te = run.standardize(x_te)\n",
    "    #x_te = special_poly_enhancement(x_te, deg_der, deg_pri, deg_cat)\n",
    "    #x_te = np.hstack((np.ones((x_te.shape[0], 1)), x_te))\n",
    "    x_te = run.polynomial_enhancement(x_te, deg_der)\n",
    "    return x, x_te\n",
    "\n",
    "def special_poly_enhancement(x_tr, deg_der, deg_pri, deg_cat):\n",
    "    x = x_tr.copy()\n",
    "    \n",
    "    arr = np.repeat([1], 30)\n",
    "    arr[0: 14] = deg_der\n",
    "    arr[14:] = deg_pri\n",
    "    arr[22] = deg_cat\n",
    "    arr = arr.tolist()\n",
    "    \n",
    "    x = np.repeat(x, arr, axis=1)\n",
    "    \n",
    "    powers = list(map(lambda pow_: range(1, pow_+1), arr))\n",
    "    powers = [p for list_p in powers for p in list_p]\n",
    "    return x ** powers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train, x_train, ids_train = helper.load_csv_data('train.csv')\n",
    "y_test, x_test, ids_test = helper.load_csv_data('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train_logistic = y_train.copy()\n",
    "y_train_logistic[y_train_logistic < 0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "half_index = int(x_train.shape[0]/2)\n",
    "x_train_half_1 = x_train[:half_index]\n",
    "x_train_half_2 = x_train[half_index:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Good models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Least squares custom degrees (4, 7, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "preprocessed_x_train = special_preprocess(x_train, deg_der=4, deg_pri=7, deg_cat=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accuracy, loss_tr, loss_te, weigths = run.cross_validation(y_train, preprocessed_x_train, 5, run.pseudo_least_squares, 1, seed=1, compute_loss=imp.rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.79282, 0.7913, 0.79394, 0.79344, 0.79384]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.793068"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(accuracy) / len(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Least squares custom degrees (8, 4, 13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preprocessed_x_train, preprocessed_x_test = special_preprocess(x_train, x_test, deg_der=8, deg_pri=4, deg_cat=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accuracy, loss_tr, loss_te, weigths = run.cross_validation(y_train, preprocessed_x_train, 5, run.pseudo_least_squares, 1, seed=1, compute_loss=imp.rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w, loss = run.pseudo_least_squares(y_train, preprocessed_x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = preprocessed_x_test @ w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = helper.predict_labels(w, preprocessed_x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "helper.create_csv_submission(ids_test, y_pred, 'least_squares_8_4_13.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.80826, 0.80734, 0.81196, 0.8071, 0.80668]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.808268"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(accuracy) / len(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic regression deg=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preprocessed_x_train = special_preprocess(x_train, deg_der=4, deg_pri=4, deg_cat=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "newton_minimzer = lambda y, tx, w: minimizers.newton_step(y, tx, w,\n",
    "            logistic.compute_gradient, logistic.compute_hessian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed logistic regression with loss 92434.4637377\n"
     ]
    }
   ],
   "source": [
    "accuracy = logistic.logistic_regression(y_train, x_train, 100, 1, newton_minimzer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model ensembling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_1(y, x_train, x_test):\n",
    "    preprocessed_x_train, preprocessed_x_test = special_preprocess(x_train, x_test, deg_der=4, deg_pri=7, deg_cat=10)\n",
    "    w, loss = run.pseudo_least_squares(y, preprocessed_x_train)\n",
    "    return preprocessed_x_test @ w\n",
    "\n",
    "def model_2(y, x_train, x_test):\n",
    "    preprocessed_x_train,preprocessed_x_test  = special_preprocess(x_train, x_test, deg_der=8, deg_pri=4, deg_cat=13)\n",
    "    w, loss = run.pseudo_least_squares(y, preprocessed_x_train)\n",
    "    return preprocessed_x_test @ w\n",
    "\n",
    "def model_3(y, x_train, x_test):\n",
    "    preprocessed_x_train,preprocessed_x_test  = special_preprocess(x_train, x_test, deg_der=4, deg_pri=4, deg_cat=4)\n",
    "    w, loss = run.pseudo_least_squares(y, preprocessed_x_train)\n",
    "    return preprocessed_x_test @ w\n",
    "\n",
    "def model_4(y, x_train, x_test):\n",
    "    preprocessed_x_train,preprocessed_x_test  = special_preprocess(x_train, x_test, deg_der=5, deg_pri=5, deg_cat=5)\n",
    "    w, loss = run.pseudo_least_squares(y, preprocessed_x_train)\n",
    "    return preprocessed_x_test @ w\n",
    "\n",
    "def model_5(y, x_train, x_test):\n",
    "    preprocessed_x_train,preprocessed_x_test  = special_preprocess(x_train, x_test, deg_der=6, deg_pri=6, deg_cat=6)\n",
    "    w, loss = run.pseudo_least_squares(y, preprocessed_x_train)\n",
    "    return preprocessed_x_test @ w\n",
    "\n",
    "def model_6(y, x_train, x_test):\n",
    "    preprocessed_x_train,preprocessed_x_test  = special_preprocess(x_train, x_test, deg_der=7, deg_pri=7, deg_cat=7)\n",
    "    w, loss = run.pseudo_least_squares(y, preprocessed_x_train)\n",
    "    return preprocessed_x_test @ w\n",
    "\n",
    "def model_7(y, x_train, x_test):\n",
    "    preprocessed_x_train,preprocessed_x_test  = special_preprocess(x_train, x_test, deg_der=8, deg_pri=8, deg_cat=8)\n",
    "    w, loss = run.pseudo_least_squares(y, preprocessed_x_train)\n",
    "    return preprocessed_x_test @ w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_ensembling(models, meta_model, x_train, y_train):\n",
    "    x = x_train.copy()\n",
    "    half_index = int(x.shape[0]/2)\n",
    "    x_half_1 = x[:half_index, :]\n",
    "    x_half_2 = x[half_index:, :]\n",
    "    \n",
    "    y_half_1 = y_train[:half_index]\n",
    "    y_half_2 = y_train[half_index:]\n",
    "    \n",
    "    results_model = [model(y_half_1, x_half_1, x_half_2) for model in models]\n",
    "    \n",
    "    new_x = np.array(results_model).T\n",
    "    \n",
    "    #new_x[new_x > 0] = 1\n",
    "    #new_x[new_x <= 0] = -1\n",
    "    \n",
    "    #summed = new_x[:1] + new_x[1:]\n",
    "    #print(new_x.shape)\n",
    "    \n",
    "    #print(summed[summed == 0].size / summed.size)\n",
    "    #new_x = run.standardize(new_x)\n",
    "    #new_x = np.concatenate((run.polynomial_enhancement(new_x[:, :1], 3), run.polynomial_enhancement(new_x[:, 1:], 4)), axis=1)\n",
    "    new_x = run.polynomial_enhancement(new_x, 4)[:, 1:]\n",
    "    #new_x = np.hstack((np.ones((new_x.shape[0], 1)), new_x))\n",
    "    \n",
    "    accuracy, loss_tr, loss_te, weigths = run.cross_validation(y_half_2, new_x, 4, meta_model, 1, seed=1, compute_loss=imp.rmse)    \n",
    "    return accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(241,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.807168, 0.804768, 0.807136, 0.807584]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies = model_ensembling([model_6, model_7], run.pseudo_least_squares, x_train, y_train)\n",
    "accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8066639999999999"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(accuracies) / len(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_ensembling_train(models, meta_model, x_train, y_train, x_test):\n",
    "    x = x_train.copy()\n",
    "    half_index = int(x.shape[0]/2)\n",
    "    x_half_1 = x[:half_index, :]\n",
    "    x_half_2 = x[half_index:, :]\n",
    "    \n",
    "    y_half_1 = y_train[:half_index]\n",
    "    y_half_2 = y_train[half_index:]\n",
    "    \n",
    "    results_model = [model(y_half_1, x_half_1, x_half_2) for model in models]\n",
    "    \n",
    "    test_stage_2 = [model(y_half_1, x_half_1, x_test) for model in models]\n",
    "    \n",
    "    new_x = np.array(results_model).T\n",
    "    new_x_test = np.array(test_stage_2).T\n",
    "    #new_x[new_x > 0] = 1\n",
    "    #new_x[new_x <= 0] = -1\n",
    "    \n",
    "    \n",
    "    \n",
    "    #summed = new_x[:1] + new_x[1:]\n",
    "    \n",
    "    #print(summed[summed == 0].size / summed.size)\n",
    "    #new_x = run.standardize(new_x)\n",
    "    #new_x_test = run.standardize(new_x_test)\n",
    "    \n",
    "    new_x = run.polynomial_enhancement(new_x, 4)\n",
    "    new_x_test = run.polynomial_enhancement(new_x_test, 4)\n",
    "    \n",
    "    w, loss = meta_model(y_half_2, new_x)\n",
    "    \n",
    "    y_pred = helper.predict_labels(w, new_x_test)\n",
    "    \n",
    "    helper.create_csv_submission(ids_test, y_pred, 'model_ensembling_2_6_7.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_ensembling_train([model_2, model_6, model_7], run.pseudo_least_squares, x_train, y_train, x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model ensembling compatibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_ensembling_train(models, meta_model, x_train, y_train, x_test):\n",
    "    x_tr = x_train.copy()\n",
    "    half_index = int(x_tr.shape[0]/2)\n",
    "    x_half_1 = x_tr[:half_index, :]\n",
    "    x_half_2 = x_tr[half_index:, :]\n",
    "    \n",
    "    y_half_1 = y_train[:half_index]\n",
    "    y_half_2 = y_train[half_index:]\n",
    "    \n",
    "    results_model = [model(y_half_1, x_half_1, x_half_2) for model in models]\n",
    "    \n",
    "    test_stage_2 = [model(y_half_1, x_half_1, x_test) for model in models]\n",
    "    \n",
    "    new_x = np.array(results_model).T\n",
    "    new_x_test = np.array(test_stage_2).T\n",
    "    #new_x[new_x > 0] = 1\n",
    "    #new_x[new_x <= 0] = -1\n",
    "    \n",
    "    \n",
    "    \n",
    "    #summed = new_x[:1] + new_x[1:]\n",
    "    \n",
    "    #print(summed[summed == 0].size / summed.size)\n",
    "    #new_x = run.standardize(new_x)\n",
    "    #new_x_test = run.standardize(new_x_test)\n",
    "    \n",
    "    new_x = run.polynomial_enhancement(new_x, 4)\n",
    "    new_x_test = run.polynomial_enhancement(new_x_test, 4)\n",
    "    \n",
    "    w, loss = meta_model(y_half_2, new_x)\n",
    "    \n",
    "    y_pred = helper.predict_labels(w, new_x_test)\n",
    "    \n",
    "    helper.create_csv_submission(ids_test, y_pred, 'model_ensembling_2_6_7.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boosting test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "ename": "LinAlgError",
     "evalue": "1-dimensional array given. Array must be at least two-dimensional",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-302-bdbf8f6c0630>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpinv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36mpinv\u001b[0;34m(a, rcond)\u001b[0m\n\u001b[1;32m   1645\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1646\u001b[0m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconjugate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1647\u001b[0;31m     \u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1648\u001b[0m     \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1649\u001b[0m     \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36msvd\u001b[0;34m(a, full_matrices, compute_uv)\u001b[0m\n\u001b[1;32m   1367\u001b[0m     \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_makearray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1368\u001b[0m     \u001b[0m_assertNoEmpty2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1369\u001b[0;31m     \u001b[0m_assertRankAtLeast2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1370\u001b[0m     \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_commonType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36m_assertRankAtLeast2\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m             raise LinAlgError('%d-dimensional array given. Array must be '\n\u001b[0;32m--> 202\u001b[0;31m                     'at least two-dimensional' % a.ndim)\n\u001b[0m\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_assertSquareness\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLinAlgError\u001b[0m: 1-dimensional array given. Array must be at least two-dimensional"
     ]
    }
   ],
   "source": [
    "test = np.array([1, 2, 3, 4])\n",
    "np.linalg.pinv(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def boosting(y_train, x_train, weights_step=0.01):\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
